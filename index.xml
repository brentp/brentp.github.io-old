<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>genomics dev blog</title>
    <link>/</link>
    <description>Recent content on genomics dev blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 20 Aug 2017 21:38:52 +0800</lastBuildDate>
    
        <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Sun, 20 Aug 2017 21:38:52 +0800</pubDate>
      
      <guid>/about/</guid>
      
        <description>&lt;p&gt;This is a blog-ish site written in hugo
Hugo is a static site engine written in Go.&lt;/p&gt;

&lt;p&gt;Learn more and contribute on &lt;a href=&#34;https://github.com/gohugoio&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Nim Hts Example</title>
      <link>/post/nim-hts-example/</link>
      <pubDate>Mon, 01 Oct 2018 13:17:00 -0600</pubDate>
      
      <guid>/post/nim-hts-example/</guid>
      
        <description>&lt;p&gt;Several folks have recently expressed interest in learning &lt;a href=&#34;https://nim-lang.org&#34;&gt;nim&lt;/a&gt; which
I have found to be very useful for genomics because it has a simple syntax like python, but
it compiles to be as fast as C. In the case of &lt;a href=&#34;https://github.com/brentp/mosdepth&#34;&gt;mosdepth&lt;/a&gt; which
is written in nim, it is faster than the competing C implementations because of choice of
algorithm.&lt;/p&gt;

&lt;p&gt;I have started using &lt;code&gt;nim&lt;/code&gt; in my day-to-day scripting to replace python, in part, so this will be
the first in a series of posts that show some relatively mundane code that I write like a script but
will compile to run very fast. Hopefully, this can be informative for people who want to start doing
some genomics data-processing with &lt;code&gt;nim&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Today, I am comparing outputs from 2 different softwares for extracting split and discordant reads
for input to lumpy. They produce very similar, but not identical results. I want to better understand
how they differ. They make relatively small output bams, so the process is to&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;read each bam into a table (like a python dict) keyed by read-name + read flag and with value of
each alignment&lt;/li&gt;
&lt;li&gt;find reads that are in 1 table and not another&lt;/li&gt;
&lt;li&gt;print the flag since that is the main &amp;ldquo;decider&amp;rdquo; of what&amp;rsquo;s included in the output.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Here is the code with comments:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-nim&#34; data-lang=&#34;nim&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tables
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; hts

&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt;
 abam:Bam
 bbam:Bam


&lt;span style=&#34;color:#75715e&#34;&gt;# two bam paths are sent in as arguments&lt;/span&gt;
open(abam, commandLineParams()&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;) 
open(bbam, commandLineParams()&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# define a simple function to use as a key in the table&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;proc &lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;key&lt;/span&gt;(aln:Record): &lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; aln.qname &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;//&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;aln.flag


&lt;span style=&#34;color:#75715e&#34;&gt;# fill a table with the key defined above and the value of the record&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;proc &lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;fill_table&lt;/span&gt;(bam:Bam): TableRef&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;,Record&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; newTable&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;, Record&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;()
  &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; aln &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; bam:
    &lt;span style=&#34;color:#75715e&#34;&gt;# have to copy since the bam parser re-uses the underlying pointer during iteration&lt;/span&gt;
    result&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;aln.key&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; aln.copy()


&lt;span style=&#34;color:#75715e&#34;&gt;# get a table for each bam.&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; atable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fill_table(abam)
&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; btable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fill_table(bbam)

&lt;span style=&#34;color:#75715e&#34;&gt;# get a seq (list) of Records that are in atbl, but not in btbl&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;proc &lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;diff&lt;/span&gt;(atbl, btbl: TableRef&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;,Record&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;): &lt;span style=&#34;color:#66d9ef&#34;&gt;seq&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Record&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#e6db74&#34;&gt;## return the alignments in a, but not in b&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; k, aln &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; atbl:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; (k &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; btbl):
      result.add(aln)

&lt;span style=&#34;color:#75715e&#34;&gt;# print out the differences. note that UFCS let&amp;#39;s us&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# use atable.diff(btable) which is equivalent to btable.diff(atable)&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; aln &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; atable.diff(btable):
  &lt;span style=&#34;color:#75715e&#34;&gt;# aln.flag is a uint16, but it has a string method defined on it so this&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# will print, e.g.: PAIRED,REVERSE,MREVERSE,READ2,SUPPLEMENTARY&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# indicating which bits are set in the flag&lt;/span&gt;

  echo aln.flag&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;note the &lt;code&gt;flag&lt;/code&gt; is actually a &lt;code&gt;uint16&lt;/code&gt; but can still print as an informative string.
This uses a method on the flag similar to python&amp;rsquo;s &lt;code&gt;__repr__&lt;/code&gt; or &lt;code&gt;__str__&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;This gives a starting-point for looking into the problem at hand.
For more info on using &lt;a href=&#34;https://github.com/brentp/hts-nim&#34;&gt;hts-nim&lt;/a&gt;, have a look at the &lt;a href=&#34;https://brentp.github.io/hts-nim/&#34;&gt;docs&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>You don&#39;t need to pileup</title>
      <link>/post/no-pile/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/no-pile/</guid>
      
        <description>&lt;p&gt;I stumbled on this (now) obvious way of doing things that I hadn&amp;rsquo;t seen
used much/at all; In a project soon to be released, we needed to quickly assay thousands
of sites from BAM/CRAM files and do a sort of cheap genotyping&amp;ndash;or allele
counting. Given this task, a common tool to reach for is the pile-up.&lt;/p&gt;

&lt;p&gt;Pile-up is pretty fast but it has to do a lot of work. Even to assay a
single site, a pileup will first get each read and a pileup structure (&lt;code&gt;bam_pileup1_t&lt;/code&gt; in htslib) for each read into memory. Each pileup structure keeps a sort of cursor in the read. This is a flexible
approach and pretty fast when assaying multiple consecutive sites. However, especially when
assaying sites more than a few bases apart, it does a lot of extra work so it&amp;rsquo;s probably faster to not use pileup.&lt;/p&gt;

&lt;p&gt;A faster way is to take each read:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;iterate over the cigar until the requested genomic position is reached.&lt;/li&gt;
&lt;li&gt;calculate the offest into the alignment (query) sequence for that position&lt;/li&gt;
&lt;li&gt;check if the query base matches the reference.&lt;/li&gt;
&lt;li&gt;discard the read.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The last item is to explicitly note that the reads are not kept in memory.
This can be done in any language that allows access to the cigar. And can be much faster
in interfaces like &lt;a href=&#34;http://pysam.readthedocs.io/en/latest/api.html&#34;&gt;pysam&lt;/a&gt; whose pileup API,
 when given a query of even 1 base will create an iterator that generates a pileup for
all positions that have an alignment that also overlaps the query location. So if a 10KB nanopore
read overlaps that position of interest, it will generate pileups for all 10K sites in that read
as well as the single site of interest.&lt;/p&gt;

&lt;p&gt;Here is an example using &lt;a href=&#34;https://github.com/brentp/hts-nim/&#34;&gt;hts-nim&lt;/a&gt; which makes it especially palatable (IMNSHO).
It queries a particular &lt;code&gt;chrom&lt;/code&gt; and &lt;code&gt;position&lt;/code&gt; and checks against the expected &lt;code&gt;ref_allele&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-nim&#34;&gt;
  for aln in bam.query(chrom, position, position + 1):
    var 
      off = aln.start
      qoff = 0
      roff_only = 0
      nalt = 0
      nref = 0

    for event in aln.cigar:
      var cons = event.consumes
      if cons.query:
        qoff += event.len
      if cons.reference:
        off += event.len
        if not cons.query:
          roff_only += event.len

      # continue until we get to the genomic position
      if off &amp;lt;= position: continue

      # since each cigar op can consume many bases
      # calc how far past the requested position
      var over = off - position - roff_only
      # get the base 
      var base = aln.base_at(qoff - over)
      if base == ref_allele:
        nref += 1
      else:
        nalt += 1

    # now nalt and nref are the allele counts ready for use.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;the final result has &lt;code&gt;nalt&lt;/code&gt; and &lt;code&gt;nref&lt;/code&gt; which can be used for genotyping. The logic could probably be simplified
a bit, but I wrote that in very short order and can now re-use. This can easily be extended
to get the base-qualities at each position (hts-nim has &lt;code&gt;aln.base_quality_at(qpos)&lt;/code&gt; to complement the &lt;code&gt;aln.base_at&lt;/code&gt; seen here) and to check for indels as well as SNPs.&lt;/p&gt;

&lt;p&gt;I haven&amp;rsquo;t seen this used elsewhere, perhaps due to the convenience of the pileup API or for lack of looking?
I may try to convert this to have a sort of API (or just a function) that allows flexible querying of
this sort that hides the cigar accounting.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Indexcov: cover your bases</title>
      <link>/post/indexcov/</link>
      <pubDate>Mon, 16 Apr 2018 13:10:07 -0600</pubDate>
      
      <guid>/post/indexcov/</guid>
      
        <description>

&lt;p&gt;This post is to introduce &lt;a href=&#34;https://github.com/brentp/goleft/tree/master/indexcov&#34;&gt;indexcov&lt;/a&gt; and answer common
question I get about interpretation.&lt;/p&gt;

&lt;p&gt;I have found that, as &lt;code&gt;indexcov&lt;/code&gt; is applied to cohorts approaching size of 100 or so, the probability that
it will reveal something very interesting (either a data artefact or large chromosomal anomaly)
approaches 1.0. For example, who knew that there were &lt;a href=&#34;https://twitter.com/ryanlayer/status/900821457604812800&#34;&gt;trisomies in Simons diversity panel?&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/brentp/goleft/tree/master/indexcov&#34;&gt;indexcov&lt;/a&gt; quickly estimates coverage for whole genome BAM and CRAM files.
It takes about 1 second per BAM. It does this by &lt;strong&gt;not parsing the BAM&lt;/strong&gt;,
instead, it uses the linear index in the BAM index. The BAM index contains
a &amp;ldquo;linear index&amp;rdquo; that, indicates the file offset (in bytes) for every 16384 bases in
the genome. &lt;code&gt;indexcov&lt;/code&gt; relies on the assumption that the the difference in file
consecutive file-offsets in the index (which indicates the amount of bytes within a 16KB region)
is a reasonable proxy for the &lt;strong&gt;coverage&lt;/strong&gt; in that 16KB region. It does some other
&lt;em&gt;sourcery&lt;/em&gt; for CRAM index files.&lt;/p&gt;

&lt;p&gt;There are many reasons this coverage estimate can be wrong. Some of those reasons are enumerated
in the &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/29048539&#34;&gt;indexcov paper&lt;/a&gt;. In practice, it seems to
work. Internally, &lt;code&gt;indexcov&lt;/code&gt; will normalize each 16KB bin to the median, so bins with &amp;ldquo;&lt;em&gt;normal&lt;/em&gt;&amp;ldquo;
coverage will have a value around 1. Calculating this normalized coverage (and then doing a PCA)
is most of the computational work that &lt;code&gt;indexcov&lt;/code&gt; performs, the rest is visualization.&lt;/p&gt;

&lt;p&gt;Given a command like (yes, it&amp;rsquo;s this simple):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;goleft indexcov -d output/ path/to/*.bam
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;output/index.html&lt;/code&gt; will show a number of plots; some are interactive and some
are static images that can be clicked to go to an interactive plot.&lt;/p&gt;

&lt;p&gt;To orient, here is X chromosome, where we expect males to have a coverage
of about 0.5 and females about 1 (since everything is scaled to 1 for diploid copy).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/x-ex.png&#34; alt=&#34;example X coverage&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The x-axis is position along the chromosome, and the y-axis is scaled coverage. This cohort has 50
so samples all shown in the same plot, each sample with it&amp;rsquo;s own color. Note we can clearly see
the group of females at coverage of 1 and males at 0.5. There&amp;rsquo;s a gap in coverage at the centromere
and some large variation, including at the start of the chromosome.&lt;/p&gt;

&lt;p&gt;In the index.html, &lt;code&gt;indexcov&lt;/code&gt; shows this plot as a static png, which, when clicked, takes the
user to an interactive version that allows hovering to see per-sample info.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;indexcov&lt;/code&gt; makes a similar plot for the Y chromosome where, again, males and females separate
cleanly. It then uses the data from the sex chromosomes to make a plot like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/sex-plot.png&#34; alt=&#34;sex plot&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Note that, among other uses, this type of plot helps to find XXY samples which are not detectable when looking
at X and Y in isolation.&lt;/p&gt;

&lt;p&gt;In a recent project, we saw this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/funky.png&#34; alt=&#34;funky plot&#34; /&gt;&lt;/p&gt;

&lt;p&gt;where there&amp;rsquo;s a sample with 3 copies of X and another sample where most cells appear to have lost the Y.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s also possible to see large (&amp;gt;10MB deletions). For example, here&amp;rsquo;s a &lt;strong&gt;deletion at the end of chr10&lt;/strong&gt; found
in a cohort of 1200 samples:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/indexcov-del.png&#34; alt=&#34;deletion plot&#34; /&gt;&lt;/p&gt;

&lt;p&gt;It takes a couple of seconds of concentration to see it, but this is 1200 samples, so we can scan
an entire genome for large events in a couple of minutes. These are the types of events that would
be embarrassing to miss, but, in fact, they are easy to miss unless you have a pipeline doing much
more expensive LOH or coverage analyses. Even depth-based CNV callers have trouble with events like these.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s another example of the &lt;a href=&#34;https://ghr.nlm.nih.gov/condition/angelman-syndrome&#34;&gt;Angelman&lt;/a&gt; &lt;strong&gt;deletion at the start of (acrocentric) chromosome 15&lt;/strong&gt; in a cohort
of 45 samples:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/indexcov-angelman.png&#34; alt=&#34;angelman coverage&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Another way to plot this is a cumulative coverage plot. The same plot above can be seen somewhat more concisely
as&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/indexcov-angelman-cum.png&#34; alt=&#34;angelman cumulate&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Since much of the chromosome is not covered due to the acrocentric chromosomal region, the y-axis starts at about 0.8
for all samples. For most samples, it does not drop until about 1. This means that most samples are covered at about
1X for 80% of the genome. We can see the angelman sample because it drops earlier, plateau&amp;rsquo;s, and then meets up with
the rest of the samples around one. This plot is a more concise way to show the data. It appears side-by-side with the
depth plot in the HTML output of indexcov.&lt;/p&gt;

&lt;h2 id=&#34;bin-outliers&#34;&gt;Bin outliers&lt;/h2&gt;

&lt;p&gt;One thing we can see from the plots above for chromosome 15 is that some samples are frequently farther from the expected
coverage of 1. For those plots, the offending samples are pink and light tan colored. These also appear as the samples with
the least vertical lines as the pass through a coverage of 1 on the proportion-covered-at plot. &lt;code&gt;indexcov&lt;/code&gt; calculates a
single value for each sample to describe this behavior; it simply counts the number of 16KB autosomal regions for which the the
sample is outside of the range of 0.85 to 1.15. It also calculates the slope of the cumulative coverage plot, but the 0.85-1-15 metric
seems to work quite well. It also calculates the proportion of bins with coverage &amp;lt; 0.15. This is useful for finding samples
with a lot of missing data. It then makes a plot of those 2 values. For the 45 sample cohort above, that looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/indexcov-bin.png&#34; alt=&#34;bin plot&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Note that there are 2 samples that are very high on the y-axis. Those correspond to the tan and pink and light-tan colored samples
that have variable coverage in the depth plots (in the HTML, this plot is hoverable so those samples are easily discoverable).&lt;/p&gt;

&lt;p&gt;Samples that are outliers like this have a &lt;em&gt;coverage bias&lt;/em&gt; that will make them problematic for CNV calling and likely other
prolems.&lt;/p&gt;

&lt;h2 id=&#34;chromosomal-differences&#34;&gt;Chromosomal Differences&lt;/h2&gt;

&lt;p&gt;Because &lt;code&gt;indexcov&lt;/code&gt; just does a simple per-sample median normalization (and because there are unknown coverage biases) some
variation in coverage still remains. This is especially apparent on chromosomes with high-GC content. For example, here is
chromosome 19, a high-GC chromosome, for the same 45-member cohort:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/indexcov-19.png&#34; alt=&#34;chr 19&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Note that there is extreme coverage variability in all samples, but especially in the tan sample. Don&amp;rsquo;t mistake
variability like this for an event, if you see a sample like that check if it&amp;rsquo;s high on the bin plot.&lt;/p&gt;

&lt;p&gt;(There does appear to be a true homozygous duplication in the rust-colored sample just after the centromere.)&lt;/p&gt;

&lt;h2 id=&#34;data-files&#34;&gt;Data Files&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;indexcov&lt;/code&gt; outputs data files (linked from the HTML). One is a ped file that contains all per-sample info:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;usual pedigree info with -9 for parents&lt;/li&gt;
&lt;li&gt;X and Y copy-number&lt;/li&gt;
&lt;li&gt;proportion of bins in and out of 0.85-1.15 range&lt;/li&gt;
&lt;li&gt;propotion of bins &amp;lt; 0.15&lt;/li&gt;
&lt;li&gt;slope of cumulative coverage line as it passes through 1.&lt;/li&gt;
&lt;li&gt;PCs 1 through 5&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;It also outputs a bed.gz file that an additional column for each sample and rows for each 16KB region in the genome so that
users can do their own analyses &lt;a href=&#34;https://twitter.com/yokofakun/status/975786108297596929&#34;&gt;and visualizations&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;use-it&#34;&gt;Use it&lt;/h2&gt;

&lt;p&gt;If you have whole genomes and haven&amp;rsquo;t used indexcov, give it a try. You can download a &lt;em&gt;truly&lt;/em&gt; static binary &lt;a href=&#34;https://github.com/brentp/goleft/releases&#34;&gt;here&lt;/a&gt;. And run it on a hundred bams in under 2 minutes like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;goleft indexcov -d output-dir/ /path/to/*.bam
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And, if you do use it, please cite &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/29048539&#34;&gt;the paper&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>mosdepth ideas</title>
      <link>/post/arrays/</link>
      <pubDate>Wed, 28 Mar 2018 20:12:07 -0600</pubDate>
      
      <guid>/post/arrays/</guid>
      
        <description>&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1739/29678184-da1f384c-88ba-11e7-9d98-df4fe3a59924.png&#34; alt=&#34;logo&#34; title=&#34;logo by tom sasani&#34; /&gt;&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m working on a new project and part of it is made possible by an observation that we
stumbled on with &lt;a href=&#34;https://github.com/brentp/mosdepth&#34;&gt;mosdepth&lt;/a&gt;. It&amp;rsquo;s something that&amp;rsquo;s obvious in retrospect
but wasn&amp;rsquo;t fully apparent to me until after &lt;code&gt;mosdepth&lt;/code&gt; was mostly written. In short, that observation is
&lt;em&gt;computers can do stuff with arrays quickly&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The longer story behind that obvious and simple observation is as follows. &lt;code&gt;mosdepth&lt;/code&gt; is a tool to calculate
depth from BAM/CRAM files. Rather than streaming out the coverage by keeping a heap of reads and keeping
a cursor in each read to indicate the position and popping reads off the heap as the cursor moves past the
end of the read and adding reads onto the heap as the genomic position advances, and &amp;hellip; [snip],
&lt;code&gt;mosdepth&lt;/code&gt; instead
allocates an array the size of the current chromosome, then considers each read one-at-a-time. For each,
it increments the read start position in the array by 1 and decrements then end position by 1 discards
that read, and proceeds with the next. Aaron used
this same algorithm in bedtools genome coverage which uses 2 arrays instead of 1. &lt;code&gt;mosdepth&lt;/code&gt;
does a bit more work for reads with deletions and reads that overlap their mate, but that&amp;rsquo;s it. Once
all reads from a chromosome are consumed and added, then the coverage is the cumulative sum of all elements
in the array.&lt;/p&gt;

&lt;p&gt;Given this array for human chromosome 1 which is over &lt;strong&gt;249 million bases&lt;/strong&gt; (or 249 million int32&amp;rsquo;s), in my laptop it takes about:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;0.125 seconds&lt;/strong&gt; to calculate this cumsum to convert the array values from start/end incr/decrs to per-base coverage&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;0.204 seconds&lt;/strong&gt; to calculate the mean coverage for each of &lt;strong&gt;111626&lt;/strong&gt; exons for all known transcripts on chromosome 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;0.756 seconds&lt;/strong&gt; to calculate quantized coverage (contiguous bins of coverage at specified depths) of &lt;code&gt;-q 0:1:2:3:4:5:6:7:8:12:16:20:25:30:40:&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;0.508&lt;/strong&gt; seconds to calculate the cumulative coverage distribution (proportion of bases covered at 1X, 2X&amp;hellip; $NX)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;hellip; and so on. So yeah, computers are good at arrays and stuff.&lt;/p&gt;

&lt;p&gt;We can add a lot of utility to &lt;code&gt;mosdepth&lt;/code&gt;, all of them in a single run and it doesn&amp;rsquo;t affect the runtime appreciably since (decompressing
and) parsing the bam dominate the run-time. Another benefit is that once everything is in the array, the times of all subsequent operations
are &lt;strong&gt;independent&lt;/strong&gt; of the depth. I didn&amp;rsquo;t realize all of these niceties until after it was mostly implemented.&lt;/p&gt;

&lt;p&gt;So, this is convenient. &lt;code&gt;mosdepth&lt;/code&gt; doesn&amp;rsquo;t have too much in the way of new ideas, it just takes full advantage. One
thing I realized later is that depth is a special case of a more generic thing we might want to measure. For depth,
we increment/decrement the start/end of each read (or the read&amp;rsquo;s component segments), but one could increment/decrement
the start/end of any event. For example the per-base locations of soft-clips/hard-clips/insertions/deletions, etc. I did
some of this in &lt;a href=&#34;https://github.com/brentp/bigly&#34;&gt;bigly&lt;/a&gt; which is based on the heap structure that we avoided with &lt;code&gt;mosdepth&lt;/code&gt;,
but next post, I&amp;rsquo;ll talk about what I&amp;rsquo;ll be working on and how it&amp;rsquo;s useful to do this in the &lt;code&gt;mosdepth&lt;/code&gt; way.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;p.s. thanks to &lt;a href=&#34;https://twitter.com/tomsasani&#34;&gt;Tom Sasani&lt;/a&gt; (AKA &lt;a href=&#34;https://www.nature.com/articles/nbt.4060&#34;&gt;sixsani&lt;/a&gt;)
for the logo and to Aaron for brainstorming sessions on what became the core of what became mosdepth&lt;/em&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Smoove</title>
      <link>/post/smoove/</link>
      <pubDate>Tue, 20 Mar 2018 16:49:22 -0600</pubDate>
      
      <guid>/post/smoove/</guid>
      
        <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/brentp/smoove&#34;&gt;smoove&lt;/a&gt; wraps existing software and adds some internal read-filtering to
&lt;strong&gt;simplify calling and genotyping structural variants&lt;/strong&gt;. It parallelizes each step as it can, for example, it
streams &lt;a href=&#34;https://github.com/arq5x/lumpy-sv&#34;&gt;lumpy&lt;/a&gt; output directly to multiple &lt;a href=&#34;https://github.com/hall-lab/svtyper&#34;&gt;svtyper&lt;/a&gt;
processes for genotyping.
It contains several sub-commands but users with cohorts of less than about 40 samples can get a
joint-called, genotyped VCF in a single command:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Bash&#34;&gt;smoove call -x --genotype --name $name --outdir . \
           -f $fasta --processes 12 --exclude $bed *.bam
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It also greatly simplifies population-level calling.
We have recently used &lt;code&gt;smoove&lt;/code&gt; to jointly call structural variants in &lt;strong&gt;2392 samples on AWS in about 1 hour of human time&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;This should work for any diploid species with a reference genome.&lt;/p&gt;

&lt;h4 id=&#34;filters-and-accuracy&#34;&gt;Filters and Accuracy&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;smoove&lt;/code&gt; uses &lt;code&gt;lumpy_filter&lt;/code&gt; from the &lt;a href=&#34;https://github.com/arq5x/lumpy-sv&#34;&gt;lumpy&lt;/a&gt;
repo to extract split (having a SA tag) and discordant (having an insert size outside of the expected range) reads as required
by lumpy. If &lt;code&gt;$sample.split.bam&lt;/code&gt; and &lt;code&gt;$sample.disc.bam&lt;/code&gt; are present (or soft-linked) to the output directory, then &lt;code&gt;smoove&lt;/code&gt; will use those
so output from &lt;a href=&#34;https://github.com/GregoryFaust/samblaster&#34;&gt;samblaster&lt;/a&gt; can be used to bypass the need for &lt;code&gt;lumpy_filter&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;It will then further filter those reads as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;reads where both ends are soft-clips are excluded, e.g. discard a read with cigar &lt;code&gt;20S106M34S&lt;/code&gt; but keep &lt;code&gt;87S123M&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;discard interchromosomal reads with &amp;gt; 3 mismatches (determined by NM sam tag).&lt;/li&gt;
&lt;li&gt;discard interchromosomal that also has an XA tag indicating alternative matches.&lt;/li&gt;
&lt;li&gt;discard interchromosomal split-reads are discarded unless the split (SA tag) goes to the same general location as the mate.&lt;/li&gt;
&lt;li&gt;remove reads in exclude regions or on excluded chromosomes.&lt;/li&gt;
&lt;li&gt;remove reads from regions where the depths of split or discordant reads is greater than 1000. This removes regions that
contribute to spurious calls.&lt;/li&gt;
&lt;li&gt;remove reads that are orphaned (dont have a mate) after all of the above filtering.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This removes more than &lt;strong&gt;80%&lt;/strong&gt; of the reads from the &lt;code&gt;.split.bam&lt;/code&gt; and &lt;code&gt;.disc.bam&lt;/code&gt; files that are sent to lumpy.
In our tests, compared to vanilla lumpy, we found
that, in a &lt;a href=&#34;http://eichlerlab.gs.washington.edu/publications/chm1-structural-variation/&#34;&gt;pac-bio derived truth set&lt;/a&gt;,
these filters removed about 4 ostensibly &lt;em&gt;true&lt;/em&gt; deletions out of 1191 while removing 120 out of 910 deletions that
were not found in the pac-bio data. There is also a considerable speed improvement and memory reduction using &lt;code&gt;smoove&lt;/code&gt;
as compared to vanilla &lt;code&gt;lumpy&lt;/code&gt;. We will do more work to filter even more reads (and perhaps add some missing ones)
to make this more efficient and accurate.&lt;/p&gt;

&lt;h4 id=&#34;usage&#34;&gt;Usage&lt;/h4&gt;

&lt;p&gt;The simplest way to get &lt;code&gt;smoove&lt;/code&gt; and all dependencies is via &lt;a href=&#34;https://hub.docker.com/r/brentp/smoove/&#34;&gt;dockerhub&lt;/a&gt; (and soon via bioconda).&lt;/p&gt;

&lt;p&gt;For a small cohort, the single command above is sufficient; for population-level calling, &lt;code&gt;smoove&lt;/code&gt; should be used to first call by
sample, or by family, or in groups of &lt;code&gt;n&lt;/code&gt; (we do this by family). Then it can extract and merge all sites from all groups (internally using
&lt;a href=&#34;https://github.com/hall-lab/svtools&#34;&gt;svtools&lt;/a&gt;). Then it can genotype at those sites (again, per sample or per small group),
and finally, it can create a square VCF using &lt;a href=&#34;https://github.com/samtools/bcftools&#34;&gt;bcftools&lt;/a&gt; merge.&lt;/p&gt;

&lt;p&gt;Each of these commands is documented in the &lt;a href=&#34;https://github.com/brentp/smoove&#34;&gt;smoove README&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;noise&#34;&gt;Noise&lt;/h4&gt;

&lt;p&gt;As indicated, I will look into additional read-filters that can be applied. If you know of or see a noise signal that could be
used to reliably remove reads that lead to spurious calls, please comment, or open an issue on the
&lt;a href=&#34;https://github.com/brentp/smoove&#34;&gt;smoove repo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In calling the 2392 samples mentioned above, it is clear that there are several avenues to explore for filtering. One noise signature that appears to be
associated with bad calls is when a variant has a low allele balance (hovering around 0.1) in many samples and never approaches the expected value
of 0.5. Though we expect mapping bias, it should not be this severe; signals like this are indicative of low-level noise causing spurious calls.
We can also look at the relative rates of split and discordant reads in these types of variants. In addition, I am working on another way to mitigate this
type of noise that is upstream of variant-calling that I will blog about soon.&lt;/p&gt;

&lt;h4 id=&#34;future&#34;&gt;Future&lt;/h4&gt;

&lt;p&gt;We may also wrap additional tools such as a depth-based CNV caller (something I plan on looking into writing this year) or other SV callers that complement
what &lt;a href=&#34;https://github.com/arq5x/lumpy-sv&#34;&gt;lumpy&lt;/a&gt; reports. Suggestions on this are also welcome.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Noise</title>
      <link>/post/noise/</link>
      <pubDate>Wed, 14 Mar 2018 19:35:37 -0600</pubDate>
      
      <guid>/post/noise/</guid>
      
        <description>&lt;p&gt;This afternoon, I did a quick analysis to attempt to find variants on the X chromosome that are under
recessive constraint&amp;ndash;that is that they appear in some non-zero frequency in females but never
occur in male. That is, without an extra copy, a variant might be embryonic lethal in males, but
could be seen in females thanks to a backup copy. I thought that these might be occurring at a
relatively high allele frequency (greater than 0.001). I encountered some surprises.&lt;/p&gt;

&lt;p&gt;A reasonable first pass is to filter to variants on X that have:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;0 homozygous alternate samples in females (or males)&lt;/li&gt;
&lt;li&gt;0 heterozygous alternate samples in males.&lt;/li&gt;
&lt;li&gt;some number of heterozygous sites in females.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This information is easily extracted from the &lt;a href=&#34;http://gnomad.broadinstitute.org/downloads&#34;&gt;gnomad exomes VCF&lt;/a&gt;
with 120K samples
as it reports &lt;code&gt;GC_Male&lt;/code&gt; and &lt;code&gt;GC_Female&lt;/code&gt;
which, for bi-allelic variants, have 3 values indicating the number of samples that
are respectively homozygous reference, heterozygous, and homozygous alternate.&lt;/p&gt;

&lt;p&gt;I created an expected proportion of alternate alleles (not samples) using the females and then used that
as the expected success rate for testing if males were depleted for the allele. Since gnomad also reports
the total number of alleles in males and females (accounting already for the fact that males only have 1 allele),
it&amp;rsquo;s simple to put this into a binomial test&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import scipy.stats as ss
from cyvcf2 import VCF
vcf = VCF(&amp;quot;gnomad.vcf.gz&amp;quot;)
for v in vcf(&amp;quot;X:2781479-155701382&amp;quot;): # exclude PAR
    gcm = v.INFO[&amp;quot;GC_Male&amp;quot;]
    gcf = v.INFO[&amp;quot;GC_Female&amp;quot;]
    success_prob = gcf[1] / float(v.INFO[&amp;quot;AN_Female&amp;quot;])
    # 0 successes == 0 males with an alternate out of AN_Male alleles with p defined by females.
    p = ss.binom_test(0, v.INFO[&amp;quot;AN_Male&amp;quot;], p=success_prob)
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are other ways to do this, but I figured this was a reasonable check to start&lt;/p&gt;

&lt;p&gt;After requiring a p-value of &amp;lt; 1e-10 to more than account for multiple testing, more than 500 variants popped
out.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://gnomad.broadinstitute.org/variant/X-14937753-T-G&#34;&gt;here&lt;/a&gt; is one of the top variants. It has an allele frequency
of 0.01553 but has never been seen as a homozygous alternate in 147,273 sampled alleles.&lt;/p&gt;

&lt;p&gt;What Aaron noticed after I sent a message to slack indicating that I&amp;rsquo;d solved the genome was that it always occurs on
the red (forward) reads in the alignment browser at the bottom of that page. Although this variant has PASS in the FILTER
field it has an FS of 172.927. &lt;code&gt;FS&lt;/code&gt; is &amp;ldquo;Phred-scaled p-value using Fisher&amp;rsquo;s exact test to detect strand bias&amp;rdquo;. High is bad.&lt;/p&gt;

&lt;p&gt;After requiring an FS &amp;lt;= 10, the number dropped dramatically, but there were still many variants. The next filter was to
require that the variant appear in gnomad whole genomes as we noticed that many of the candidates did not appear in whole genomes.
To have a high enough p-value to pass the 1e-10 threshold, the allele frequency should be high enough to appear in 12K samples.
After this, we also found that the remaining variants were frequently filtered in gnomad genomes VCF so we required them to be
present in the genomes, not flagged, and we again checked that there were 0 male heterozygotes or homozygous alternates in the
whole genomes as well. After this &lt;strong&gt;7 variants remained&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t inted to pursue this, but it was a fun afternoon&amp;rsquo;s tinkering. Here are those variants in case anyone has some
insight:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;X	2836140	rs202219772	G	A
X	48270249	rs377690870	G	A
X	101473058	rs782534766	A	G
X	119293216	rs782542106	C	CG
X	119293240	rs199940228	G	A
X	134988581	rs145404090	A	G
X	153461539	.	C	T
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://gist.github.com/brentp/e8b400bf8bfb297c8d49f9673e32d2e4#file-male-depleted-x-py&#34;&gt;here is the script used to find these&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>