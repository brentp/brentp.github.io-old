<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>genomics dev blog</title>
    <link>/</link>
    <description>Recent content on genomics dev blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 20 Aug 2017 21:38:52 +0800</lastBuildDate>
    
        <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Sun, 20 Aug 2017 21:38:52 +0800</pubDate>
      
      <guid>/about/</guid>
      
        <description>&lt;p&gt;This is a blog-ish site written in hugo
Hugo is a static site engine written in Go.&lt;/p&gt;

&lt;p&gt;Learn more and contribute on &lt;a href=&#34;https://github.com/gohugoio&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>How critical is it to have a full trio for rare-disease analysis?</title>
      <link>/post/trio-duo-solo/</link>
      <pubDate>Fri, 21 Jun 2019 10:11:26 -0600</pubDate>
      
      <guid>/post/trio-duo-solo/</guid>
      
        <description>&lt;p&gt;&lt;/p&gt;

&lt;p&gt;This is a continuation of my &lt;a href=&#34;https://brentp.github.io/post/variant-filter/&#34;&gt;previous post&lt;/a&gt; where I looked at filtering variants in rare disease trios.&lt;/p&gt;

&lt;p&gt;In building out &lt;a href=&#34;https://github.com/brentp/slivar&#34;&gt;slivar&lt;/a&gt;, I have largely focused on trios&amp;ndash;where mom, dad, and affected kid are present. I assumed that with only a single affected sample, it would substantially reduce the &lt;em&gt;solve-rate&lt;/em&gt; and increase the false-positive rate, in which a ostensibly &lt;em&gt;causal variant&lt;/em&gt; was mis-categorized or leave so many candidate variants that the solve-rate would be lowered.&lt;/p&gt;

&lt;p&gt;A recent &lt;em&gt;Cell&lt;/em&gt; paper &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/31130284&#34;&gt;looked at &amp;gt; 2200 Saudi families where a proband had rare disease&lt;/a&gt;. The apparent solve-rate was no different for singleton samples than for trios; this could be due to the choice of when trio-sequencing was needed, but, still, interesting. Also, &lt;a href=&#34;https://twitter.com/hdashnow&#34;&gt;Harriet&lt;/a&gt;, who has just joined the Quinlan lab, is co-author on &lt;a href=&#34;https://www.nature.com/articles/ejhg2017123&#34;&gt;a paper&lt;/a&gt; that, evaluates singleton exomes and finds that gene-lists created by clinicians facilitate variant prioritization.&lt;/p&gt;

&lt;p&gt;I ran an &lt;em&gt;in silico&lt;/em&gt; experiment where a set of high-quality candidate variants is found with each of 149 trios with exome sequencing. Then each family is computationally reduced to a &lt;em&gt;duo&lt;/em&gt;&amp;ndash;with only 1 parent, and then a &lt;em&gt;solo&lt;/em&gt;, with just the proband.&lt;/p&gt;

&lt;p&gt;Without a team of clinicians, one can&amp;rsquo;t know the true causal variants, even with trios, but the &lt;em&gt;solo&lt;/em&gt; analysis should be able to recover a superset of the variants from the &lt;em&gt;trio&lt;/em&gt; analysis. As that superset becomes too large, it becomes less plausible that &lt;em&gt;solo&lt;/em&gt; sequencing is a viable analysis strategy. This is imperfect, but can give a general idea of the task.&lt;/p&gt;

&lt;p&gt;This analysis includes &lt;em&gt;de novo&lt;/em&gt;, &lt;em&gt;single-site, autosomal recessive&lt;/em&gt;, &lt;em&gt;x-linked recessive&lt;/em&gt;, and &lt;em&gt;compound heterozygote&lt;/em&gt; inheritance patterns. &lt;code&gt;slivar&lt;/code&gt; has been updated to better support &lt;em&gt;duo&lt;/em&gt; and &lt;em&gt;solo&lt;/em&gt; families with the latest (pending) release.&lt;/p&gt;

&lt;p&gt;The filtering is on only:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;inheritance pattern&lt;/li&gt;
&lt;li&gt;depth&lt;/li&gt;
&lt;li&gt;genotype-quality&lt;/li&gt;
&lt;li&gt;allele-balance&lt;/li&gt;
&lt;li&gt;gnomAD allele frequency&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For example, the filters for &lt;em&gt;de novo&lt;/em&gt; variants are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;trio: &lt;code&gt;$HQ &amp;amp;&amp;amp; mom.hom_ref &amp;amp;&amp;amp; dad.hom_ref &amp;amp;&amp;amp; kid.het &amp;amp;&amp;amp; kid.AB &amp;gt; 0.2 &amp;amp;&amp;amp; kid.AB &amp;lt; 0.8&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;duo: &lt;code&gt;$HQ &amp;amp;&amp;amp; mom.hom_ref &amp;amp;&amp;amp; kid.het &amp;amp;&amp;amp; kid.AB &amp;gt; 0.2 &amp;amp;&amp;amp; kid.AB &amp;lt; 0.8&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;solo: &lt;code&gt;$HQ &amp;amp;&amp;amp; kid.het &amp;amp;&amp;amp; kid.AB &amp;gt; 0.2 &amp;amp;&amp;amp; kid.AB &amp;lt; 0.8&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;where &lt;code&gt;$HQ&lt;/code&gt; ensures that each sample has &lt;code&gt;depth &amp;gt;= 7&lt;/code&gt; and &lt;code&gt;GQ &amp;gt;= 10&lt;/code&gt; and that &lt;code&gt;variant.FILTER == &#39;PASS&#39;&lt;/code&gt; and the variant is at a low allele-frequency (0.001 for &lt;em&gt;de novo&lt;/em&gt; and 0.01 for recessive) in gnomAD. Below is the result of counting the number of variants that pass filters for each inheritance mode for 149 trios, from which we also create 149 duos (kid, mom) and solos (just kid).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/trio-solo-duo.png&#34; alt=&#34;trio solo duo&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In the plot above, each point represents a proband with the y-position being the number of passing variants and the color indicating trio, duo, or solo, each subplot is a different inheritance mode.&lt;/p&gt;

&lt;p&gt;I have placed &lt;code&gt;denovo&lt;/code&gt; and &lt;code&gt;compound-het&lt;/code&gt; on the top row because these are the 2 modes where the number of candidates for &lt;code&gt;solo&lt;/code&gt; is too high to be feasible. For other inheritance modes, the number is quite reasonable.&lt;/p&gt;

&lt;h2 id=&#34;additional-filtering-for-solo-de-novo-and-compound-het&#34;&gt;Additional Filtering for solo &lt;em&gt;de novo&lt;/em&gt; and &lt;em&gt;compound-het&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;200 variants, as in the case of solo &lt;em&gt;de novo&lt;/em&gt; in the plot above seems too many to reasonably evaluate, we can reduce this number by:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;limiting to functional variants&lt;/li&gt;
&lt;li&gt;lowering the gnomAD allele-frequency thresholds&lt;/li&gt;
&lt;li&gt;raising depth and genotype-quality thresholds&lt;/li&gt;
&lt;li&gt;filtering on TOPmed allele-frequency&lt;/li&gt;
&lt;li&gt;limiting to genes of interest&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;of those, the last is the most difficult as it requires either knowledge of the phenotype in each of the 149 probands or trust in a gene-wide score such as pLI or gene-damage-index. We can, however, limit to a set of genes previously associated with (any) disease using &lt;a href=&#34;http://compbio.charite.de/jenkins/job/hpo.annotations.monthly/lastSuccessfulBuild/artifact/annotation/genes_to_diseases.txt&#34;&gt;this file&lt;/a&gt; which uses OMIM disease annotations.&lt;/p&gt;

&lt;p&gt;In order to limit to &amp;ldquo;functional variants&amp;rdquo;, I used only variants with a variant-effect-predictor &lt;a href=&#34;https://uswest.ensembl.org/info/docs/tools/vep/index.html&#34;&gt;VEP&lt;/a&gt; of &lt;code&gt;MODERATE&lt;/code&gt; or &lt;code&gt;HIGH&lt;/code&gt;. This includes missense variants, so it is still pretty permissive.&lt;/p&gt;

&lt;h4 id=&#34;compound-heterozygotes-in-solo-samples&#34;&gt;Compound heterozygotes in solo samples&lt;/h4&gt;

&lt;p&gt;The number of compound heterozygotes in a single sample could be reduced to an average of &lt;strong&gt;21 candidate variants (so 10-11 genes)&lt;/strong&gt; by requiring functional variants with 1 or fewer homozygous alternates in gnomad controls and limiting both the topmed (via dbsnp) and gnomAD popmax allele frequency to &amp;lt; 0.005. Since this number was low enough with strict, but sane filters, I did not explore further filtering for compound heterozygotes.&lt;/p&gt;

&lt;h4 id=&#34;de-novo-in-solo-samples&#34;&gt;De novo in solo samples&lt;/h4&gt;

&lt;p&gt;Since a putative &lt;em&gt;de novo&lt;/em&gt; variant in a solo analysis is simply a high-quality, rare heterozygote, the findings here will also translate to autosomal dominant since that would have the same constraint. The starting point here is about 200 variants per sample, as shown by the cluster of orange points in the top-left (&lt;em&gt;de novo&lt;/em&gt; subplot from the figure above. Here, I&amp;rsquo;m not (currently)recommending a best-practices approach, just exploring the possibility of reducing this to a more reasonable number of candidate variants.&lt;/p&gt;

&lt;p&gt;The plot below shows the number of candidate &amp;ldquo;&lt;em&gt;de novo&lt;/em&gt;&amp;rdquo; variants in a &lt;em&gt;solo&lt;/em&gt; sample.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/solo.png&#34; alt=&#34;solo&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Except for the final column, each column along the x-axis is a more stringent subset of the one that precedes it&lt;/strong&gt;. The left-most column, in yellow continues from the orange cluster in the &lt;em&gt;de novo&lt;/em&gt; subplot of the first figure by requiring, from left-to-right:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;solo_denovo&lt;/code&gt; (yellow): &lt;code&gt;HIGH&lt;/code&gt; or &lt;code&gt;MODERATE&lt;/code&gt; impact according to VEP&lt;/li&gt;
&lt;li&gt;&lt;code&gt;solo_denovo_gnomad&lt;/code&gt; (brown): frequency in gnomad controls &amp;lt; 0.005 and number of hom-alts in gnomad &amp;lt;= 1&lt;/li&gt;
&lt;li&gt;&lt;code&gt;solo_denovo_dp_gq&lt;/code&gt; (pink): depth &amp;gt; 10 (was depth &amp;gt; 6)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;solo_denovo_topmed&lt;/code&gt;(gray): frequency in topmed &amp;lt; 0.02 (can catch problems with lifting gnomAD to hg38)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;solo_denovo_HIGH...&lt;/code&gt; (red): impact is HIGH according to VEP or the variant is missense and has a sift score or polyphen score that predicts it to be damaging/deleterious&lt;/li&gt;
&lt;li&gt;&lt;code&gt;solo_denovo_HIGH&lt;/code&gt; (blue): impact is HIGH according to VEP&lt;/li&gt;
&lt;li&gt;&lt;code&gt;solo_denovo_disease_gene&lt;/code&gt; (green): the variant exists in a gene associated with some disease in OMIM. this is a subset of the gray column.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The final (green) column is a subset of the gray column; it shows an alternative strategy that looks at gene, rather than at the function of variants (as in red and blue).&lt;/p&gt;

&lt;p&gt;Intuitively, the &lt;font color=&#34;red&#34;&gt;red&lt;/font&gt; and &lt;font color=&#34;green&#34;&gt;green&lt;/font&gt; columns seem the most reasonable balance of stringency and likely recall. For example, we are unlikely to solve a rare-disease case if the variant is not MODERATE or HIGH impact accordign to VEP. At a mean of about 70 and 35 variants per sample, respectively, these are not ideal, but 35 is a number of variants that a clinician or analyst could reasonbly evaluate.&lt;/p&gt;

&lt;p&gt;Note that the drop from pink to gray indicates the effect of using TOPmed annotations that are not visible in GRCh37 but common (at more than 2% allele frequency) in hg38.&lt;/p&gt;

&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;It is possible to recover a small candidate-set by applying minimal filters to a parent-child duo. To me, this is the most useful result of this analysis which I think is also a novel observation.&lt;/li&gt;
&lt;li&gt;For a &lt;em&gt;solo&lt;/em&gt; (singleton) sample, given the number of candidate variants, it is unlikely to &amp;ldquo;solve&amp;rdquo; a &lt;em&gt;de novo&lt;/em&gt; or dominant case without prior knowledge&amp;ndash;for example a small set of genes of interest. This will be unsurprising to most, still the analysis in the 2nd figure above does show how much the set of candidate variants can be reduced.&lt;/li&gt;
&lt;li&gt;For a &lt;em&gt;solo&lt;/em&gt; sample, it &lt;strong&gt;does&lt;/strong&gt; seem possible, based on the number of candidate variants to solve a recessive case&amp;ndash;either a single-site autosomal recessive or a compound heterozygote.&lt;/li&gt;
&lt;li&gt;Due to &lt;a href=&#34;https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1707-2&#34;&gt;dark regions&lt;/a&gt;, variants that are common in hg38 are completely absent in GRCh37 so lifted gnomAD annotations will not filter some common variants. The shift from pink to gray in the 2nd figure shows this; the reduction (after previous filtering) is ~10-15%.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Thanks to &lt;a href=&#34;https://twitter.com/hdashnow&#34;&gt;Harriet&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/aaronquinlan&#34;&gt;Aaron&lt;/a&gt;, Amelia, &lt;a href=&#34;https://twitter.com/PubSnips&#34;&gt;Matt&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/jxchong&#34;&gt;Jessica&lt;/a&gt; for feedback on these analyses.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>filtering variants in rare disease trios</title>
      <link>/post/variant-filter/</link>
      <pubDate>Wed, 01 May 2019 12:25:04 -0600</pubDate>
      
      <guid>/post/variant-filter/</guid>
      
        <description>&lt;p&gt;&lt;/p&gt;

&lt;p&gt;In rare, mendelian disease research, given a trio of an affected kid, healthy mom and healthy dad, we
seek genetic variation that can explain the &amp;ldquo;phenotype&amp;rdquo; in the kid. In this scenario,
either &lt;a href=&#34;https://medlineplus.gov/ency/article/002052.htm&#34;&gt;recessive&lt;/a&gt; or
&lt;a href=&#34;https://www.cancer.gov/publications/dictionaries/genetics-dictionary/def/de-novo-mutation&#34;&gt;de novo (dominant)&lt;/a&gt;
could match the inheritance pattern.&lt;/p&gt;

&lt;p&gt;We expect between 0 and 2 true &lt;strong&gt;de novo&lt;/strong&gt; variants per exome, but given the vagaries of sequencing,
we can find many more and it&amp;rsquo;s unclear how many recessive (compound or single-site) variants we should expect
per exome and what type of filtering is required to get that to a reasonable level. This post is to look at
various filtering strategies in the context of rare disease trios. I did this to educate myself on what type
of filtering is effective. And filtering &lt;strong&gt;is&lt;/strong&gt; needed, because, for example, a trio in my test-cohort would have ~150
putative &lt;em&gt;de novo&lt;/em&gt; variants if we looked only at genotype.&lt;/p&gt;

&lt;p&gt;The filters (beyond the genotypes for inheritance pattern) that I&amp;rsquo;ll consider are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;FILTER&lt;/code&gt;: variant FILTER field is PASS&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GQ&lt;/code&gt;: genotype quality &amp;gt; 10&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AB&lt;/code&gt;: allele balance (alt alleles / (ref + alt)) between 0.25 and 0.75&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DP&lt;/code&gt;: depth &amp;gt; 7&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gnomad_popmax_af&lt;/code&gt;: &lt;a href=&#34;https://gnomad.broadinstitute.org/&#34;&gt;gnomAD&lt;/a&gt; population max allele frequence &amp;lt; 0.001&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gnomad_filter&lt;/code&gt;: variant must have a PASS filter in gnomAD&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These filters will be applied singly and then combined so we can evaluate how each reduces the number of putative
variants to consider. The exact values I have chosen are arbitrary, but defensible and changing them to other sane
values does not change the conclusions at all (or the actual resulting counts much). And especially when multiple
criteria are combined as they will be in a real analysis, the exact cutoff tends to matter less.&lt;/p&gt;

&lt;p&gt;Note that since this is in the context of rare disease, we can require the variant to be extremely rare in gnomAD,
if, instead, we are just looking for &lt;em&gt;de novo&lt;/em&gt; variants that may not contribute to disease, the allele frequency filter
would be less useful.&lt;/p&gt;

&lt;p&gt;Not for nothing, I&amp;rsquo;ll do this analysis using &lt;a href=&#34;https://github.com/brentp/slivar&#34;&gt;slivar&lt;/a&gt; and the full command to do the
entire analysis will be at the end of the post, but I&amp;rsquo;ll describe each step as well.&lt;/p&gt;

&lt;p&gt;For &lt;em&gt;recessive&lt;/em&gt; inheritance mode, we&amp;rsquo;ll integrate variants within a gene and use phase-by-inheritance to ensure that
the variants are on opposite haplotypes. That will also be done relatively automatically by &lt;a href=&#34;https://github.com/brentp/slivar/wiki/rare-disease#compound-heterozygotes&#34;&gt;slivar&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The test-cohort is a set of 149 trios jointly-called using GATK. The analyses below will not look at the functional status of the variant,
doing so would further cull the number of candidate causal variants.&lt;/p&gt;

&lt;h2 id=&#34;denovo&#34;&gt;Denovo&lt;/h2&gt;

&lt;p&gt;The plot below shows the entirety of the results for the &lt;em&gt;de novo&lt;/em&gt; analysis.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Each point represents a trio&lt;/li&gt;
&lt;li&gt;The x-axis (and the colors) separate different possible filtering strategies, generally moving to more strigent left to right.&lt;/li&gt;
&lt;li&gt;The y-axis indicates the putative number of &lt;strong&gt;de novo&lt;/strong&gt; variants.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;/img/variant-filter-denovo.png&#34; alt=&#34;de novo plot&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The left-most, red cluster labelled &lt;strong&gt;DN&lt;/strong&gt; is the number of variants that are found using only the genotypes&amp;ndash;the kid must be heterozygous and
the parents homozgyous reference.&lt;/p&gt;

&lt;p&gt;Then, moving right:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;blue (DN_pass_not_multiallelic): if we require variants to have a PASS FILTER, we can already dramatically reduce the number of variants.&lt;/li&gt;
&lt;li&gt;green (DN_AB): requires an allele balance in the kid &amp;gt; 0.25 and &amp;lt; 0.75 and 1 or fewer total alternate counts in the parents.&lt;/li&gt;
&lt;li&gt;purple (DN_depth_GQ): requires all samples to have depth &amp;gt; 7 and genotype quality &amp;gt; 10&lt;/li&gt;
&lt;li&gt;orange (DN_gnomad): requires the variant to be &amp;lsquo;PASS&amp;rsquo; in gnomAD and to have a population max allele frequency &amp;lt; 0.001&lt;/li&gt;
&lt;li&gt;yellow (DN_AB_depth): combines the &lt;code&gt;DN_AB&lt;/code&gt; and &lt;code&gt;DN_depth_GQ&lt;/code&gt; filters.&lt;/li&gt;
&lt;li&gt;brown (denovo): combines the &lt;code&gt;DN_AB_depth&lt;/code&gt; and &lt;code&gt;DN_gnomad&lt;/code&gt; and &lt;code&gt;DN_pass_not_multiallelic&lt;/code&gt; filters&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that the inset zooms in on the final 2 sets of variants (&lt;code&gt;DN_AB_depth&lt;/code&gt; and &lt;code&gt;denovo&lt;/code&gt;). In reality, a researcher is likely to
examine only variants in the &lt;code&gt;denovo&lt;/code&gt; group, meaning that she can examine between 0 and 4 variants per sample.&lt;/p&gt;

&lt;p&gt;Also note that although the depth and allele balance filters (in yellow) still leave a couple of samples with &amp;gt; 100 candidate variants
those are removed when the additional gnomAD filters are applied.&lt;/p&gt;

&lt;h3 id=&#34;combining-more-lenient-filters&#34;&gt;Combining more lenient filters&lt;/h3&gt;

&lt;p&gt;That shows how effective combining depth, allele balance, gnomAD allele frequency and FILTER can be. And the blue swarm shows that GATK
is in fact, a very good caller, yielding very few bad (spurious &lt;strong&gt;de novo&lt;/strong&gt;) calls that have a PASS filter.&lt;/p&gt;

&lt;p&gt;To demonstrate this combination effect further, we compare the final &lt;code&gt;denovo&lt;/code&gt; set of calls from above with a &lt;em&gt;lenient&lt;/em&gt; set that
requires only:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;depth 5 or more (instead of 7)&lt;/li&gt;
&lt;li&gt;genotype quality of 5 or more (instead of 10)&lt;/li&gt;
&lt;li&gt;allele balance between 0.2 and 0.8 (instead of 0.25 and 0.75)&lt;/li&gt;
&lt;li&gt;gnomAD allele frequency &amp;lt; 0.01 (instead of 0.001)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These are set low enough to make an analyst squirm, but not so low as to be unreasonable.&lt;/p&gt;

&lt;p&gt;This increases the total number of &lt;em&gt;de novo&lt;/em&gt; calls from 172 in the set plotted above to 188, meaning that this yields 1 additional
candidate &lt;em&gt;de novo&lt;/em&gt; for about every three trios. In short, relaxing constraints might be a reasonable strategy from the start because
once a number of filters are combined, the likelihood of a questionable variant sneaking through are low.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt; that this has not yet filtered on the functional status (missense/stop-gained/etc.) of the variant, which would lower the number
even more.&lt;/p&gt;

&lt;h2 id=&#34;recessive-variants&#34;&gt;Recessive Variants&lt;/h2&gt;

&lt;p&gt;Recall that recessive variants are inherited on different haplotypes, either at a single site or as a compound heterozygote. In order
to call compound heterozygotes, we must aggregate variants by gene and then phase by inheritance. Given 2 sites in a compound het in a
trio with unaffected parents and affected kid:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;kid: 0/1, mom: 0/1, dad: 0/0&lt;/li&gt;
&lt;li&gt;kid: 0/1, mom: 0/0, dad: 0/1&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;we know that the kid inherited the alternate allele at site 1 from mom and at site 2 from dad and therefore, they must be on
different haplotypes and could therefore knock out both copies of the gene.&lt;/p&gt;

&lt;p&gt;In order to find sites like this, we must first find sites that are heterozygotes in the kid and 1 and only 1 parent and
then use the phase-by-inheritance logic and gene aggregation to find pairs like above. An additional wrinkle is that
we will also allow 1 of the pair of sites to be a &lt;em&gt;de novo&lt;/em&gt;; though we can&amp;rsquo;t phase the &lt;em&gt;de novo&lt;/em&gt;, we expect
there to be few enough putative &lt;em&gt;de novo&lt;/em&gt;&amp;rsquo;s that it should not yield too many false positives.&lt;/p&gt;

&lt;p&gt;Finally, we can also find sites that are simple autosomal recessives where both parents are heterozygotes, and the kid
is homozygous alternate, along with x-linked recessives where a son receives a variant allele from mom that appears as a
heterozygote in mom and as homozygous alternate in the son (since he has only 1 copy of X).&lt;/p&gt;

&lt;p&gt;The plot below shows the entirety of the results for the recessive analysis.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Each point represents a trio&lt;/li&gt;
&lt;li&gt;The x-axis (and the colors) separate different possible filtering strategies, generally moving to more strigent left to right.&lt;/li&gt;
&lt;li&gt;The y-axis indicates the putative number of recessive variants.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;/img/variant-filter-recessive.png&#34; alt=&#34;recessive plot&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In this plot, the left-most, red swarm, labeled &amp;lsquo;AR&amp;rsquo;, is the meta-set of variants that could possibly be any type of recessive variant. It only requires kid to be heterozygous or homozygous and mom or dad to be heterozygous and neither mom nor dad to be homozygous alternate&lt;/p&gt;

&lt;p&gt;Then continuing right across the plot:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;blue (AR_pass_not_MA): limits the &lt;code&gt;AR&lt;/code&gt; variants to PASS and not multi-allelic&lt;/li&gt;
&lt;li&gt;green (AR_AB): limits the &lt;code&gt;AR&lt;/code&gt; variants to have AB &amp;gt; 0.25 and AB &amp;lt; 0.75 for sites where the kid is heterozygous (remember this set also incluces variants where the kid is hom-alt)&lt;/li&gt;
&lt;li&gt;purple (AR_depth): limits AR variants to have depth &amp;gt; 7.&lt;/li&gt;
&lt;li&gt;orange (AR_AB_depth_GQ): requires variants to pass &lt;code&gt;AR_AB&lt;/code&gt; and &lt;code&gt;AR_depth&lt;/code&gt; and requires kid, mom, and dad to have GQ &amp;gt; 10&lt;/li&gt;
&lt;li&gt;AR_gnomad (yellow): requires the &lt;code&gt;AR&lt;/code&gt; variant to have a populatiom max allele frequency &amp;lt; 0.005 in gnomad.&lt;/li&gt;
&lt;li&gt;AR_filtered (brown): requires &lt;code&gt;AR_AB_depth&lt;/code&gt;, &lt;code&gt;AR_pass_not_MA&lt;/code&gt;, and &lt;code&gt;AR_gnomad&lt;/code&gt; &amp;ndash; so depth &amp;gt; 7, GQ &amp;gt; 10, PASS and gnomad frequency &amp;lt; 0.005&lt;/li&gt;
&lt;li&gt;autorec (pink): this requires &lt;code&gt;AR_filtered&lt;/code&gt; and mom and dad to be heterozygous and kid homozygous alternate &amp;ndash; so this is a single-site recessive&lt;/li&gt;
&lt;li&gt;XLR (gray): X-Linked-Recessive. requires the mom to be het, dad hom ref, and kid male and hom-alt, PASS, on the X chromosome, depth &amp;gt; 7, GQ &amp;gt; 10, mom AB &amp;gt; 0.2 and &amp;lt; 0.8.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;compound_het&lt;/code&gt;: this takes the &lt;code&gt;AR_filtered&lt;/code&gt; variants and the &lt;code&gt;denovo&lt;/code&gt; variants from above and aggregates by gene and phases-by-inheritance.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;autorec&lt;/code&gt;, &lt;code&gt;XLR&lt;/code&gt;, and &lt;code&gt;compound_het&lt;/code&gt; are what an analyst would examine. Although the base-line is much higher here, filtering with gnomad (yellow) is
very effective, dropping the number of variants from ~10,000 to ~500. The additional drop to compound-het (red) shows the power of phase-by-inheritance. Note that
the numbers for compound-hets are &lt;strong&gt;variants not pairs&lt;/strong&gt; so in this cohort, we&amp;rsquo;d look at fewer than 5 genes per trio, on average. Again, remember that this
does not consider the functional effect of the variant so that would further reduce the number of variants here.&lt;/p&gt;

&lt;p&gt;On average, an analyst would have to look at about &amp;lt; 10 single-site autosomal recessives (pink), 1 or 2 x-linked-recessive variants (gray) and about 5 compound-het pairs per trio.
In addition to the 1-2 &lt;em&gt;de novo&lt;/em&gt; variants per trio, this simple filtering results in 15 high-quality candidates for the most common analyses
performed in rare disease research.&lt;/p&gt;

&lt;h2 id=&#34;slivar&#34;&gt;Slivar&lt;/h2&gt;

&lt;p&gt;All of the filtering described above was done with one &lt;a href=&#34;https://github.com/brentp/slivar&#34;&gt;slivar&lt;/a&gt; command followed by an additional one to call compound heterozygotes.
&lt;code&gt;slivar&lt;/code&gt; allows users to write simple (javascript) expressions that get applied to every trio (or sample or user-specified group) inferred from a pedigree file in the VCF.&lt;/p&gt;

&lt;p&gt;Below is an &lt;strong&gt;especially hairy&lt;/strong&gt; command because it applies every filtering strategy plotted above. For actual research, only the final, combined commands
are needed, so please use the simple commands
documented &lt;a href=&#34;https://github.com/brentp/slivar/wiki/rare-disease#full-analysis-for-trios-with-unaffected-parents&#34;&gt;here&lt;/a&gt; that will be effectively identical to this.&lt;/p&gt;

&lt;p&gt;However, for the sake of showing the power and flexibility of &lt;code&gt;slivar&lt;/code&gt;, here is the full command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;slivar expr --vcf $bcf --ped $ped \$
    --pass-only \$
    -g /home/brentp/src/slivar/gnomad.hg38.zip \$
    -o vcfs/$cohort.bcf \$
    --trio &amp;quot;trio_specific:mom.alts &amp;gt; 0 || dad.alts &amp;gt; 0 || kid.alts &amp;gt; 0&amp;quot; \$
    --trio &amp;quot;DN:mom.alts == 0 &amp;amp;&amp;amp; dad.alts == 0 &amp;amp;&amp;amp; kid.alts == 1&amp;quot; \$
    --trio &amp;quot;DN_pass_not_multiallelic:hasSample(INFO, &#39;DN&#39;, kid.id) &amp;amp;&amp;amp; variant.FILTER == &#39;PASS&#39; &amp;amp;&amp;amp; (!variant.is_multiallelic)&amp;quot; \$
    --trio &amp;quot;DN_depth_GQ:hasSample(INFO, &#39;DN&#39;, kid.id) &amp;amp;&amp;amp; kid.DP &amp;gt; 7 &amp;amp;&amp;amp; mom.DP &amp;gt; 7 &amp;amp;&amp;amp; dad.DP &amp;gt; 7 &amp;amp;&amp;amp; mom.GQ &amp;gt; 10 &amp;amp;&amp;amp; dad.GQ &amp;gt; 10 &amp;amp;&amp;amp; kid.GQ &amp;gt; 10&amp;quot; \$
    --trio &amp;quot;DN_AB:hasSample(INFO, &#39;DN&#39;, kid.id) &amp;amp;&amp;amp; kid.AB &amp;gt; 0.25 &amp;amp;&amp;amp; kid.AB &amp;lt; 0.75 &amp;amp;&amp;amp; ((mom.AD[1] + dad.AD[1]) &amp;lt; 2)&amp;quot; \$
    --trio &amp;quot;DN_AB_depth:hasSample(INFO, &#39;DN_AB&#39;, kid.id) &amp;amp;&amp;amp; hasSample(INFO, &#39;DN_depth_GQ&#39;, kid.id)&amp;quot; \$
    --trio &amp;quot;DN_gnomad:hasSample(INFO, &#39;DN&#39;, kid.id) &amp;amp;&amp;amp; !(&#39;gnomad_popmax_af_filter&#39; in INFO) &amp;amp;&amp;amp; INFO.gnomad_popmax_af &amp;lt; 0.001&amp;quot; \$
    --trio &amp;quot;denovo:hasSample(INFO, &#39;DN_gnomad&#39;, kid.id) &amp;amp;&amp;amp; hasSample(INFO, &#39;DN_AB_depth&#39;, kid.id) &amp;amp;&amp;amp; hasSample(INFO, &#39;DN_pass_not_multiallelic&#39;, kid.id)&amp;quot; \$
    --trio &amp;quot;lenient_denovo:hasSample(INFO, &#39;DN_pass_not_multiallelic&#39;, kid.id) &amp;amp;&amp;amp; kid.DP &amp;gt; 5 &amp;amp;&amp;amp; mom.DP &amp;gt; 5 &amp;amp;&amp;amp; dad.DP &amp;gt; 5 &amp;amp;&amp;amp; mom.GQ &amp;gt; 5 &amp;amp;&amp;amp; dad.GQ &amp;gt; 5 &amp;amp;&amp;amp; kid.GQ &amp;gt; 5 &amp;amp;&amp;amp; kid.AB &amp;gt; 0.2 &amp;amp;&amp;amp; kid.AB &amp;lt; 0.8 &amp;amp;&amp;amp; INFO.gnomad_popmax_af &amp;lt; 0.01 &amp;amp;&amp;amp; !(&#39;gnomad_popmax_af_filter&#39; in INFO)&amp;quot; \$
    --trio &amp;quot;AR:(mom.alts == 1 || dad.alts == 1) &amp;amp;&amp;amp; kid.alts &amp;gt;= 1 &amp;amp;&amp;amp; mom.alts != -1 &amp;amp;&amp;amp; dad.alts != -1 &amp;amp;&amp;amp; mom.alts != 2 &amp;amp;&amp;amp; dad.alts != 2 &amp;amp;&amp;amp; kid.alts &amp;gt; 0&amp;quot; \$
    --trio &amp;quot;AR_pass_not_MA:hasSample(INFO, &#39;AR&#39;, kid.id) &amp;amp;&amp;amp; variant.FILTER == &#39;PASS&#39; &amp;amp;&amp;amp; (!variant.is_multiallelic)&amp;quot; \$
    --trio &amp;quot;AR_depth:hasSample(INFO, &#39;AR&#39;, kid.id) &amp;amp;&amp;amp; kid.DP &amp;gt; 7 &amp;amp;&amp;amp; mom.DP &amp;gt; 7 &amp;amp;&amp;amp; dad.DP &amp;gt; 7&amp;quot; \$
    --trio &amp;quot;AR_AB:hasSample(INFO, &#39;AR&#39;, kid.id) &amp;amp;&amp;amp; ((kid.alts == 1) == (kid.AB &amp;gt; 0.25 &amp;amp;&amp;amp; kid.AB &amp;lt; 0.75))&amp;quot; \$
    --trio &amp;quot;AR_AB_depth_GQ:hasSample(INFO, &#39;AR_AB&#39;, kid.id) &amp;amp;&amp;amp; hasSample(INFO, &#39;AR_depth&#39;, kid.id) &amp;amp;&amp;amp;  kid.GQ &amp;gt; 10 &amp;amp;&amp;amp; mom.GQ &amp;gt; 10 &amp;amp;&amp;amp; dad.GQ &amp;gt; 10&amp;quot; \$
    --trio &amp;quot;AR_gnomad:hasSample(INFO, &#39;AR&#39;, kid.id) &amp;amp;&amp;amp; !(&#39;gnomad_popmax_af_filter&#39; in INFO) &amp;amp;&amp;amp; INFO.gnomad_popmax_af &amp;lt; 0.005&amp;quot; \$
    --trio &amp;quot;AR_filtered:hasSample(INFO, &#39;AR_AB_depth_GQ&#39;, kid.id) &amp;amp;&amp;amp; hasSample(INFO, &#39;AR_pass_not_MA&#39;, kid.id) &amp;amp;&amp;amp; hasSample(INFO, &#39;AR_gnomad&#39;, kid.id)&amp;quot; \$
    --trio &amp;quot;autorec:hasSample(INFO, &#39;AR_filtered&#39;, kid.id) &amp;amp;&amp;amp; kid.alts == 2 &amp;amp;&amp;amp; mom.alts == 1 &amp;amp;&amp;amp; dad.alts == 1&amp;quot; \$
    --trio &amp;quot;XLR:mom.alts == 1 &amp;amp;&amp;amp; dad.alts == 0 &amp;amp;&amp;amp; kid.alts &amp;gt;= 1 &amp;amp;&amp;amp; variant.FILTER == &#39;PASS&#39; &amp;amp;&amp;amp; (!variant.is_multiallelic) &amp;amp;&amp;amp; (variant.CHROM == &#39;chrX&#39; || variant.CHROM == &#39;X&#39;) &amp;amp;&amp;amp; INFO.gnomad_popmax_af &amp;lt; 0.01 &amp;amp;&amp;amp; mom.DP &amp;gt; 10 &amp;amp;&amp;amp; dad.DP &amp;gt; 7 &amp;amp;&amp;amp; kid.DP &amp;gt; 7 &amp;amp;&amp;amp; kid.sex == &#39;male&#39; &amp;amp;&amp;amp; kid.GQ &amp;gt; 10 &amp;amp;&amp;amp; mom.GQ &amp;gt; 10 &amp;amp;&amp;amp; dad.GQ &amp;gt; 10 &amp;amp;&amp;amp; mom.AB &amp;gt; 0.2 &amp;amp;&amp;amp; mom.AB &amp;lt; 0.8 &amp;amp;&amp;amp; kid.AB &amp;gt; 0.3&amp;quot; \$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;note the &lt;code&gt;--trio&lt;/code&gt; lines that indicate an expression using &lt;code&gt;mom&lt;/code&gt;, &lt;code&gt;dad&lt;/code&gt;, &lt;code&gt;kid&lt;/code&gt; preceded by a label like &lt;code&gt;DN&lt;/code&gt; which were used as the plot labels above
and which &lt;code&gt;slivar&lt;/code&gt; injects into the INFO of the output vcf whenever there is a passing expression.&lt;/p&gt;

&lt;p&gt;The command to do the compound heterozygote filtering is:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bcftools csq -s - --ncsq 40 -g $gff -l -f $fasta vcfs/$cohort.bcf -O u \
  | slivar compound-hets -f BCSQ -i 2 --sample-field AR_filtered --sample-field denovo -p $ped &amp;gt; vcfs/$cohort.ch.vcf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;which uses &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/28205675&#34;&gt;bcftools csq&lt;/a&gt; to quickly annotate with gene (and
variant functional consequence which we haven&amp;rsquo;t used in this analysis). &lt;code&gt;slivar&lt;/code&gt; then gets the &lt;code&gt;BCSQ&lt;/code&gt; field
and extracts the gene name from the &lt;code&gt;2&lt;/code&gt;nd pipe-delimited field (-i 2) and uses that gene for aggregation.&lt;/p&gt;

&lt;p&gt;Again, it&amp;rsquo;s recommended to follow the instructions &lt;a href=&#34;https://github.com/brentp/slivar/wiki/rare-disease#compound-heterozygotes&#34;&gt;here&lt;/a&gt;,
but the code to do this full analysis on your own VCF is &lt;a href=&#34;https://gist.github.com/brentp/4ab295b6740eab3ddf802a84914ae254&#34;&gt;here&lt;/a&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Static</title>
      <link>/post/static/</link>
      <pubDate>Thu, 28 Feb 2019 11:32:22 -0700</pubDate>
      
      <guid>/post/static/</guid>
      
        <description>&lt;p&gt;After recent twitter discussions about usable software, I thought that one thing I could do to
relieve a common problem of users of my software would be to build static binaries.
I know this would be helpful because I never get any questions/bugs about installs with
&lt;a href=&#34;https://github.com/brentp/vcfanno&#34;&gt;vcfanno&lt;/a&gt; or &lt;a href=&#34;https://github.com/brentp/goleft&#34;&gt;indexcov&lt;/a&gt;
for which I provide static binaries (thanks to use of #golang) even though they are (I think) widely used.&lt;/p&gt;

&lt;p&gt;Since most of my tools are command-line apps, that rely on htslib this can be difficult. I ended up
using a docker image based on alpine linux and building an htslib without libcurl. Alpine linux uses
musl so we can avoid the warnings/errors seen when trying to use a binary
built with a new version of (g)libc on a system with an older (g)libc.&lt;/p&gt;

&lt;p&gt;The docker image is &lt;a href=&#34;https://hub.docker.com/r/brentp/musl-hts-nim&#34;&gt;musl-hts-nim&lt;/a&gt; and, using that, I made
a static binary so that, given a nim file, for example &lt;a href=&#34;https://github.com/brentp/hts-nim-tools/issues/5#issuecomment-462097499&#34;&gt;this one&lt;/a&gt; where I recently helped Ming (note in that issue, Ming had problems with libhts.so which would have been avoided with a static binary), we can
create a static binary with:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ hts_nim_static_builder -s ./atac.nim --deps &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;hts@&amp;gt;=0.2.7&amp;#34;&lt;/span&gt; --deps &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;binaryheap&amp;#34;&lt;/span&gt;
#&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This will create a static binary in &lt;code&gt;atac&lt;/code&gt;:
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ ldd ./atac
    statically linked
$ file ./atac
    ./atac: ELF &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;-bit LSB shared object, x86-64, version &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;SYSV&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;, dynamically linked, not stripped
#&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;hts_nim_static_builder&lt;/code&gt; is avaiable &lt;a href=&#34;https://github.com/brentp/hts-nim/releases/tag/v0.2.8&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;See the &lt;a href=&#34;https://github.com/brentp/hts-nim#static-builds&#34;&gt;README section&lt;/a&gt; for more information and advanced usage.&lt;/p&gt;

&lt;p&gt;I hope that this will make using &lt;a href=&#34;https://github.com/brentp/hts-nim&#34;&gt;hts-nim&lt;/a&gt; even more enticing for building command-line tools
that utilize htslib.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Hts Nim Sugar</title>
      <link>/post/hts-nim-sugar/</link>
      <pubDate>Fri, 25 Jan 2019 10:15:01 -0700</pubDate>
      
      <guid>/post/hts-nim-sugar/</guid>
      
        <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/brentp/hts-nim&#34;&gt;hts-nim&lt;/a&gt; is a library that allows one to use &lt;a href=&#34;https://www.htslib.org/&#34;&gt;htslib&lt;/a&gt; via the &lt;a href=&#34;https://nim-lang.org&#34;&gt;nim&lt;/a&gt; programming language.
Nim is a garbage-collected language that compiles to C and often has similar performance.
I have become very productive in &lt;code&gt;nim&lt;/code&gt; and especially in &lt;code&gt;hts-nim&lt;/code&gt; and there are by now, at least a few other users of &lt;code&gt;hts-nim&lt;/code&gt;.
This post is to show how one particular feature of nim enables users to write their own functions that will be used no differently than
&lt;code&gt;hts-nim&lt;/code&gt;&amp;rsquo;s provided functionality.&lt;/p&gt;

&lt;p&gt;Currently, in order to access the format (sample) fields in a VCF, one must first allocate a &lt;code&gt;seq&lt;/code&gt; (something like a typed python list) that gets filled.
The example below shows a code stub to extract the &lt;code&gt;DP&lt;/code&gt; (depth) and &lt;code&gt;GQ&lt;/code&gt; (genotype quality) fields for each sample into those pre-allocated &lt;code&gt;seq&lt;/code&gt;s.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-nim&#34; data-lang=&#34;nim&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; dps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; newSeq&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int32&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;()
&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; gqs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; newSeq&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int32&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;()
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; variant &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; vcf:
    doAssert variant.format.get(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DP&amp;#34;&lt;/span&gt;, dps) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; Status.OK
    doAssert variant.format.get(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;GQ&amp;#34;&lt;/span&gt;, gqs) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; Status.OK
    &lt;span style=&#34;color:#75715e&#34;&gt;# do stuff with dps and gqs ...&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This lets &lt;code&gt;hts-nim&lt;/code&gt; fill the &lt;code&gt;dps&lt;/code&gt; and &lt;code&gt;gqs&lt;/code&gt; sequences without allocating memory to provides maximal
performance. It&amp;rsquo;s not much of a burden, but it might be nice to have a function that just returns the values and raises
an error if the field is not found so that pre-allocation is not necesary.&lt;/p&gt;

&lt;p&gt;Since nim has &lt;a href=&#34;https://en.wikipedia.org/wiki/Uniform_Function_Call_Syntax&#34;&gt;universal function call syntax (UFCS)&lt;/a&gt;,
it&amp;rsquo;s easy to write some &lt;em&gt;sugar&lt;/em&gt; that can be used to get values without pre-allocating if that&amp;rsquo;s what&amp;rsquo;s required.
Here&amp;rsquo;s how I&amp;rsquo;d write that (though see note at end of post).&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-nim&#34; data-lang=&#34;nim&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;proc &lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;ints&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;(f:FORMAT, field: &lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;): &lt;span style=&#34;color:#66d9ef&#34;&gt;seq&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int32&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; vals &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; newSeq&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int32&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;()
  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; variant.format.get(field, vals) &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; Status.OK:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;raise&lt;/span&gt; newException(KeyError, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;error getting field:&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; field &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;. &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;Status.OK
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; vals&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This will throw an exception if the requested field does not exist. Note that the &lt;code&gt;*&lt;/code&gt; after &lt;code&gt;ints&lt;/code&gt; means
the function is exported for use outside the currrent module, which is what we want here.&lt;/p&gt;

&lt;p&gt;This function could be in a file named &lt;code&gt;sugar.nim&lt;/code&gt; and then could be used as:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-nim&#34; data-lang=&#34;nim&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; hts&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;vcf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; .&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;sugar

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; variant &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; vcf:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; dps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; variant.format.ints(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DP&amp;#34;&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;# note these could raise exceptions.&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; gqs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; variant.format.ints(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;GQ&amp;#34;&lt;/span&gt;)
    &lt;span style=&#34;color:#75715e&#34;&gt;# do stuff with dps and gqs ...&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This shows the &lt;code&gt;UFCS&lt;/code&gt; as &lt;code&gt;ints(variant.format, &amp;quot;DP&amp;quot;)&lt;/code&gt; is equivalent to &lt;code&gt;variant.format.ints(&amp;quot;DP&amp;quot;)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;This means that users are not limited to the syntax and functionality that &lt;code&gt;hts-nim&lt;/code&gt; provides, they can
write their own functions and use them as ergonomically as those that are part of hts-nim. Since hts-nim
errs on the side of efficiency rather than ergonomics, functions like these could make some nice syntactic
sugar for using &lt;code&gt;hts-nim&lt;/code&gt; as a sort of scripting language for processing genomic data.&lt;/p&gt;

&lt;h2 id=&#34;side-note&#34;&gt;side note.&lt;/h2&gt;

&lt;p&gt;The above sugar function &lt;code&gt;ints&lt;/code&gt; could be written more succinctly using nim&lt;code&gt;s&lt;/code&gt;result&lt;code&gt;variable along with the
fact that&lt;/code&gt;seq&lt;code&gt;s are never&lt;/code&gt;nil` as:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-nim&#34; data-lang=&#34;nim&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;proc &lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;ints&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;(f:FORMAT, field: &lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;): &lt;span style=&#34;color:#66d9ef&#34;&gt;seq&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int32&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; variant.format.get(field, result) &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; Status.OK:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;raise&lt;/span&gt; newException(KeyError, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;error getting field:&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; field &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;. &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;Status.OK&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;where result will be initalized by nim and set to the proper size (and filled) by hts-nim.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>get the least out of your CRAM files</title>
      <link>/post/cram-speed/</link>
      <pubDate>Thu, 11 Oct 2018 13:39:21 -0600</pubDate>
      
      <guid>/post/cram-speed/</guid>
      
        <description>&lt;p&gt;This post is highlight the speed benefit of &lt;a href=&#34;https://samtools.github.io/hts-specs/CRAMv3.pdf&#34;&gt;CRAM&lt;/a&gt; files over BAM files as it seems
to not be widely used.&lt;/p&gt;

&lt;p&gt;CRAM files are often about 50% of the size of an identical BAM for lossless compression largely due to not saving the
sequence of each read, instead keeping only the delta to the reference sequence for the alignment. Additional savings can be gained from
lossy compression of base-qualities and read-names.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;htslib.org&#34;&gt;htslib&lt;/a&gt; implementation of CRAM has an additional advantage beyond file size: &lt;strong&gt;speed&lt;/strong&gt;. It allows the user to specify
which of the pieces of the alignment will be needed and it only decodes those. (While this is possible in BAM format, for example as
implemented in &lt;a href=&#34;https://github.com/JohnLonginotto/pybam&#34;&gt;pybam&lt;/a&gt; it is not available for BAM via &lt;code&gt;htslib&lt;/code&gt;.) This control can
greatly speed processing when only a few pieces of the alignment are needed. This is quite useful since CRAM parsing can otherwise be
the bottleneck for much genomics work.&lt;/p&gt;

&lt;p&gt;In short, the most costly fields to decode are:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;base-qualities&lt;/li&gt;
&lt;li&gt;sequence&lt;/li&gt;
&lt;li&gt;aux tags&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;It&amp;rsquo;s possible to get better speed and parallelization by not decoding combinations of these. The plot below shows
&lt;strong&gt;time on the Y-axis&lt;/strong&gt; (lower is better) that it took to iterate through chromosome 20 of my test cram
for &lt;strong&gt;exclude::thread combinations on the X-axis&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/cram_exclude.png&#34; alt=&#34;times plot&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The bars a grouped by the excluded fields and colored by the number of decompression threads used.&lt;/p&gt;

&lt;p&gt;Interested readers can study this in more detail, but the key points are:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;It&amp;rsquo;s possible to get a 2X speed improvement simply by not parsing the base qualities (QUAL).&lt;/li&gt;
&lt;li&gt;If you don&amp;rsquo;t need SEQ, QUAL (base-qualities), AUX (tags like NM, SA, etc) and RG (read-groups) you can get a 3 to 4X speedup.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This is part of what makes &lt;a href=&#34;https://github.com/brentp/mosdepth&#34;&gt;mosdepth&lt;/a&gt; so fast to calculate depth on CRAM as it does not need
the base-qualities, sequence or read-groups. That&amp;rsquo;s &lt;a href=&#34;https://github.com/brentp/mosdepth/issues/2&#34;&gt;how I learned about&lt;/a&gt; this feature of CRAM.&lt;/p&gt;

&lt;p&gt;We have recently used this to speed up &lt;a href=&#34;https://github.com/hall-lab/svtyper&#34;&gt;svtyper&lt;/a&gt; which uses pysam; you can see how to do that &lt;a href=&#34;https://github.com/hall-lab/svtyper/commit/b43902c9bb5295d880b2c9fe8f8b29d973b82131#diff-2dee31fbd1190eb77e963360893ea86aR127&#34;&gt;here&lt;/a&gt;
And we&amp;rsquo;ve added it to &lt;a href=&#34;https://github.com/arq5x/lumpy-sv&#34;&gt;lumpy&lt;/a&gt; to make pre-processing alignments about twice as fast for CRAM.&lt;/p&gt;

&lt;p&gt;These options are available from the commandline samtools via &lt;code&gt;--input-format-options required_fields=####&lt;/code&gt; which is documented &lt;a href=&#34;http://www.htslib.org/doc/samtools.html&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I have gisted the nim code to do these timings the the python script for plotting &lt;a href=&#34;https://gist.github.com/brentp/213f214dd5677dd447150e62e2e360f5&#34;&gt;here&lt;/a&gt;
in case anyone wants to try various combinations.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Using Nim to count sequence-motifs in a BAM</title>
      <link>/post/nim-mundane2/</link>
      <pubDate>Thu, 04 Oct 2018 09:23:24 -0600</pubDate>
      
      <guid>/post/nim-mundane2/</guid>
      
        <description>&lt;p&gt;This is the 2nd post describing mundane uses of &lt;a href=&#34;https://nim-lang.org&#34;&gt;nim&lt;/a&gt; in day-to-day genomics.&lt;/p&gt;

&lt;p&gt;The first post is &lt;a href=&#34;https://brentp.github.io/post/nim-hts-example/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For today&amp;rsquo;s mundane task, a colleague asked me to count the occurence of 2 k-mers of length 39 in
each of 603 BAMs of 60X coverage. We don&amp;rsquo;t care about partial matches or allowing mismatches so this
is a pretty simple task. There are more efficient computational methods for this, but I wrote the
simplest version, verified that it ran in &amp;lt; 2 hours for a single bam and then ran it overnight on
a single machine with 64 CPUs and sent the results in the morning.&lt;/p&gt;

&lt;p&gt;The kmers we actually used are redacted to protect the innocent.&lt;/p&gt;

&lt;p&gt;The code does the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;implements a reverse-complement function and uses it on the 2 query sequences.&lt;/li&gt;
&lt;li&gt;opens a BAM file for the path that is given as an argument to the program.&lt;/li&gt;
&lt;li&gt;iterates over the bam and counts the presence of each forward or reverse-complemented kmer.&lt;/li&gt;
&lt;li&gt;prints out the bam and the count of times each kmer was observed.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Again, there are better algorithms for sequencer- matching (though the string-matching implementation in nim must be pretty efficient),
but this took about 15 minutes to code and was fast enough to set running. Here is the code with explanatory comments:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-nim&#34; data-lang=&#34;nim&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; strutils
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; hts
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; kmer

&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; aseq &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;some other dna sequence&amp;#34;&lt;/span&gt;.toUpperAscii
&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; bseq &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;some other DNA sequence&amp;#34;&lt;/span&gt;.toUpperAscii

&lt;span style=&#34;color:#75715e&#34;&gt;# write a quick reverse-complement function&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;proc &lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;complement&lt;/span&gt;(s:&lt;span style=&#34;color:#66d9ef&#34;&gt;char&lt;/span&gt;): &lt;span style=&#34;color:#66d9ef&#34;&gt;char&lt;/span&gt; {.inline.} &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; s &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;C&amp;#39;&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;G&amp;#39;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; s &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;G&amp;#39;&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;C&amp;#39;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; s &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;A&amp;#39;&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;T&amp;#39;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; s &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;T&amp;#39;&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;A&amp;#39;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; s

&lt;span style=&#34;color:#66d9ef&#34;&gt;proc &lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;reverse_complement&lt;/span&gt;(xs: &lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;): &lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; newString(xs.len)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; xs:
    &lt;span style=&#34;color:#75715e&#34;&gt;# high == len - 1&lt;/span&gt;
    result&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;xs.high&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;i&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; complement(x)

&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; raseq &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; aseq.reverse_complement
&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; rbseq &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; bseq.reverse_complement

&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; commandLineParams()&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; bam: Bam
open(bam, path, threads&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; acount &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; bcount &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# this gets filled with the sequence for each read.&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; sequence: &lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; aln &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; bam:
    &lt;span style=&#34;color:#75715e&#34;&gt;# check flags to avoid double-counting&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; aln.flag.dup: &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; aln.flag.supplementary: &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# fill the `sequence` string with the values from this alignment&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;discard&lt;/span&gt; aln.sequence(sequence)

    acount &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; sequence.count(aseq)
    acount &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; sequence.count(raseq)

    bcount &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; sequence.count(bseq)
    bcount &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; sequence.count(rbseq)

&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; base &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; path.split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# just print the final file, not the full directory&lt;/span&gt;
echo base&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;base.high&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;acount &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;bcount
&lt;span style=&#34;color:#75715e&#34;&gt;#&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
</description>
      
    </item>
    
    <item>
      <title>Nim Hts Example</title>
      <link>/post/nim-hts-example/</link>
      <pubDate>Mon, 01 Oct 2018 13:17:00 -0600</pubDate>
      
      <guid>/post/nim-hts-example/</guid>
      
        <description>&lt;p&gt;Several folks have recently expressed interest in learning &lt;a href=&#34;https://nim-lang.org&#34;&gt;nim&lt;/a&gt; which
I have found to be very useful for genomics because it has a simple syntax like python, but
it compiles to be as fast as C. In the case of &lt;a href=&#34;https://github.com/brentp/mosdepth&#34;&gt;mosdepth&lt;/a&gt; which
is written in nim, it is faster than the competing C implementations because of choice of
algorithm.&lt;/p&gt;

&lt;p&gt;I have started using &lt;code&gt;nim&lt;/code&gt; in my day-to-day scripting to replace python, in part, so this will be
the first in a series of posts that show some relatively mundane code that I write like a script but
will compile to run very fast. Hopefully, this can be informative for people who want to start doing
some genomics data-processing with &lt;code&gt;nim&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Today, I am comparing outputs from 2 different softwares for extracting split and discordant reads
for input to lumpy. They produce very similar, but not identical results. I want to better understand
how they differ. They make relatively small output bams, so the process is to&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;read each bam into a table (like a python dict) keyed by read-name + read flag and with value of
each alignment&lt;/li&gt;
&lt;li&gt;find reads that are in 1 table and not another&lt;/li&gt;
&lt;li&gt;print the flag since that is the main &amp;ldquo;decider&amp;rdquo; of what&amp;rsquo;s included in the output.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Here is the code with comments:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-nim&#34; data-lang=&#34;nim&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tables
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; hts

&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt;
 abam:Bam
 bbam:Bam


&lt;span style=&#34;color:#75715e&#34;&gt;# two bam paths are sent in as arguments&lt;/span&gt;
open(abam, commandLineParams()&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;) 
open(bbam, commandLineParams()&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# define a simple function to use as a key in the table&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;proc &lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;key&lt;/span&gt;(aln:Record): &lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; aln.qname &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;//&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;aln.flag


&lt;span style=&#34;color:#75715e&#34;&gt;# fill a table with the key defined above and the value of the record&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;proc &lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;fill_table&lt;/span&gt;(bam:Bam): TableRef&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;,Record&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; newTable&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;, Record&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;()
  &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; aln &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; bam:
    &lt;span style=&#34;color:#75715e&#34;&gt;# have to copy since the bam parser re-uses the underlying pointer during iteration&lt;/span&gt;
    result&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;aln.key&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; aln.copy()


&lt;span style=&#34;color:#75715e&#34;&gt;# get a table for each bam.&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; atable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fill_table(abam)
&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; btable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fill_table(bbam)

&lt;span style=&#34;color:#75715e&#34;&gt;# get a seq (list) of Records that are in atbl, but not in btbl&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;proc &lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;diff&lt;/span&gt;(atbl, btbl: TableRef&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;,Record&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;): &lt;span style=&#34;color:#66d9ef&#34;&gt;seq&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Record&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#e6db74&#34;&gt;## return the alignments in a, but not in b&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; k, aln &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; atbl:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; (k &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; btbl):
      result.add(aln)

&lt;span style=&#34;color:#75715e&#34;&gt;# print out the differences. note that UFCS let&amp;#39;s us&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# use atable.diff(btable) which is equivalent to btable.diff(atable)&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; aln &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; atable.diff(btable):
  echo aln.flag
  &lt;span style=&#34;color:#75715e&#34;&gt;# aln.flag is a uint16, but it has a string method defined on it so this&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# will print, e.g.: PAIRED,REVERSE,MREVERSE,READ2,SUPPLEMENTARY&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# indicating which bits are set in the flag&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;note the &lt;code&gt;flag&lt;/code&gt; is actually a &lt;code&gt;uint16&lt;/code&gt; but can still print as an informative string.
This uses a method on the flag similar to python&amp;rsquo;s &lt;code&gt;__repr__&lt;/code&gt; or &lt;code&gt;__str__&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;This gives a starting-point for looking into the problem at hand.
For more info on using &lt;a href=&#34;https://github.com/brentp/hts-nim&#34;&gt;hts-nim&lt;/a&gt;, have a look at the &lt;a href=&#34;https://brentp.github.io/hts-nim/&#34;&gt;docs&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>You don&#39;t need to pileup</title>
      <link>/post/no-pile/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/no-pile/</guid>
      
        <description>&lt;p&gt;I stumbled on this (now) obvious way of doing things that I hadn&amp;rsquo;t seen
used much/at all; In a project soon to be released, we needed to quickly assay thousands
of sites from BAM/CRAM files and do a sort of cheap genotyping&amp;ndash;or allele
counting. Given this task, a common tool to reach for is the pile-up.&lt;/p&gt;

&lt;p&gt;Pile-up is pretty fast but it has to do a lot of work. Even to assay a
single site, a pileup will first get each read and a pileup structure (&lt;code&gt;bam_pileup1_t&lt;/code&gt; in htslib) for each read into memory. Each pileup structure keeps a sort of cursor in the read. This is a flexible
approach and pretty fast when assaying multiple consecutive sites. However, especially when
assaying sites more than a few bases apart, it does a lot of extra work so it&amp;rsquo;s probably faster to not use pileup.&lt;/p&gt;

&lt;p&gt;A faster way is to take each read:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;iterate over the cigar until the requested genomic position is reached.&lt;/li&gt;
&lt;li&gt;calculate the offest into the alignment (query) sequence for that position&lt;/li&gt;
&lt;li&gt;check if the query base matches the reference.&lt;/li&gt;
&lt;li&gt;discard the read.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The last item is to explicitly note that the reads are not kept in memory.
This can be done in any language that allows access to the cigar. And can be much faster
in interfaces like &lt;a href=&#34;http://pysam.readthedocs.io/en/latest/api.html&#34;&gt;pysam&lt;/a&gt; whose pileup API,
 when given a query of even 1 base will create an iterator that generates a pileup for
all positions that have an alignment that also overlaps the query location. So if a 10KB nanopore
read overlaps that position of interest, it will generate pileups for all 10K sites in that read
as well as the single site of interest.&lt;/p&gt;

&lt;p&gt;Here is an example using &lt;a href=&#34;https://github.com/brentp/hts-nim/&#34;&gt;hts-nim&lt;/a&gt; which makes it especially palatable (IMNSHO).
It queries a particular &lt;code&gt;chrom&lt;/code&gt; and &lt;code&gt;position&lt;/code&gt; and checks against the expected &lt;code&gt;ref_allele&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-nim&#34;&gt;
  for aln in bam.query(chrom, position, position + 1):
    var 
      off = aln.start
      qoff = 0
      roff_only = 0
      nalt = 0
      nref = 0

    for event in aln.cigar:
      var cons = event.consumes
      if cons.query:
        qoff += event.len
      if cons.reference:
        off += event.len
        if not cons.query:
          roff_only += event.len

      # continue until we get to the genomic position
      if off &amp;lt;= position: continue

      # since each cigar op can consume many bases
      # calc how far past the requested position
      var over = off - position - roff_only
      # get the base 
      var base = aln.base_at(qoff - over)
      if base == ref_allele:
        nref += 1
      else:
        nalt += 1

    # now nalt and nref are the allele counts ready for use.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;the final result has &lt;code&gt;nalt&lt;/code&gt; and &lt;code&gt;nref&lt;/code&gt; which can be used for genotyping. The logic could probably be simplified
a bit, but I wrote that in very short order and can now re-use. This can easily be extended
to get the base-qualities at each position (hts-nim has &lt;code&gt;aln.base_quality_at(qpos)&lt;/code&gt; to complement the &lt;code&gt;aln.base_at&lt;/code&gt; seen here) and to check for indels as well as SNPs.&lt;/p&gt;

&lt;p&gt;I haven&amp;rsquo;t seen this used elsewhere, perhaps due to the convenience of the pileup API or for lack of looking?
I may try to convert this to have a sort of API (or just a function) that allows flexible querying of
this sort that hides the cigar accounting.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Indexcov: cover your bases</title>
      <link>/post/indexcov/</link>
      <pubDate>Mon, 16 Apr 2018 13:10:07 -0600</pubDate>
      
      <guid>/post/indexcov/</guid>
      
        <description>

&lt;p&gt;This post is to introduce &lt;a href=&#34;https://github.com/brentp/goleft/tree/master/indexcov&#34;&gt;indexcov&lt;/a&gt; and answer common
question I get about interpretation.&lt;/p&gt;

&lt;p&gt;I have found that, as &lt;code&gt;indexcov&lt;/code&gt; is applied to cohorts approaching size of 100 or so, the probability that
it will reveal something very interesting (either a data artefact or large chromosomal anomaly)
approaches 1.0. For example, who knew that there were &lt;a href=&#34;https://twitter.com/ryanlayer/status/900821457604812800&#34;&gt;trisomies in Simons diversity panel?&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/brentp/goleft/tree/master/indexcov&#34;&gt;indexcov&lt;/a&gt; quickly estimates coverage for whole genome BAM and CRAM files.
It takes about 1 second per BAM. It does this by &lt;strong&gt;not parsing the BAM&lt;/strong&gt;,
instead, it uses the linear index in the BAM index. The BAM index contains
a &amp;ldquo;linear index&amp;rdquo; that, indicates the file offset (in bytes) for every 16384 bases in
the genome. &lt;code&gt;indexcov&lt;/code&gt; relies on the assumption that the the difference in file
consecutive file-offsets in the index (which indicates the amount of bytes within a 16KB region)
is a reasonable proxy for the &lt;strong&gt;coverage&lt;/strong&gt; in that 16KB region. It does some other
&lt;em&gt;sourcery&lt;/em&gt; for CRAM index files.&lt;/p&gt;

&lt;p&gt;There are many reasons this coverage estimate can be wrong. Some of those reasons are enumerated
in the &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/29048539&#34;&gt;indexcov paper&lt;/a&gt;. In practice, it seems to
work. Internally, &lt;code&gt;indexcov&lt;/code&gt; will normalize each 16KB bin to the median, so bins with &amp;ldquo;&lt;em&gt;normal&lt;/em&gt;&amp;ldquo;
coverage will have a value around 1. Calculating this normalized coverage (and then doing a PCA)
is most of the computational work that &lt;code&gt;indexcov&lt;/code&gt; performs, the rest is visualization.&lt;/p&gt;

&lt;p&gt;Given a command like (yes, it&amp;rsquo;s this simple):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;goleft indexcov -d output/ path/to/*.bam
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;output/index.html&lt;/code&gt; will show a number of plots; some are interactive and some
are static images that can be clicked to go to an interactive plot.&lt;/p&gt;

&lt;p&gt;To orient, here is X chromosome, where we expect males to have a coverage
of about 0.5 and females about 1 (since everything is scaled to 1 for diploid copy).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/x-ex.png&#34; alt=&#34;example X coverage&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The x-axis is position along the chromosome, and the y-axis is scaled coverage. This cohort has 50
so samples all shown in the same plot, each sample with it&amp;rsquo;s own color. Note we can clearly see
the group of females at coverage of 1 and males at 0.5. There&amp;rsquo;s a gap in coverage at the centromere
and some large variation, including at the start of the chromosome.&lt;/p&gt;

&lt;p&gt;In the index.html, &lt;code&gt;indexcov&lt;/code&gt; shows this plot as a static png, which, when clicked, takes the
user to an interactive version that allows hovering to see per-sample info.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;indexcov&lt;/code&gt; makes a similar plot for the Y chromosome where, again, males and females separate
cleanly. It then uses the data from the sex chromosomes to make a plot like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/sex-plot.png&#34; alt=&#34;sex plot&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Note that, among other uses, this type of plot helps to find XXY samples which are not detectable when looking
at X and Y in isolation.&lt;/p&gt;

&lt;p&gt;In a recent project, we saw this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/funky.png&#34; alt=&#34;funky plot&#34; /&gt;&lt;/p&gt;

&lt;p&gt;where there&amp;rsquo;s a sample with 3 copies of X and another sample where most cells appear to have lost the Y.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s also possible to see large (&amp;gt;10MB deletions). For example, here&amp;rsquo;s a &lt;strong&gt;deletion at the end of chr10&lt;/strong&gt; found
in a cohort of 1200 samples:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/indexcov-del.png&#34; alt=&#34;deletion plot&#34; /&gt;&lt;/p&gt;

&lt;p&gt;It takes a couple of seconds of concentration to see it, but this is 1200 samples, so we can scan
an entire genome for large events in a couple of minutes. These are the types of events that would
be embarrassing to miss, but, in fact, they are easy to miss unless you have a pipeline doing much
more expensive LOH or coverage analyses. Even depth-based CNV callers have trouble with events like these.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s another example of the &lt;a href=&#34;https://ghr.nlm.nih.gov/condition/angelman-syndrome&#34;&gt;Angelman&lt;/a&gt; &lt;strong&gt;deletion at the start of (acrocentric) chromosome 15&lt;/strong&gt; in a cohort
of 45 samples:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/indexcov-angelman.png&#34; alt=&#34;angelman coverage&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Another way to plot this is a cumulative coverage plot. The same plot above can be seen somewhat more concisely
as&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/indexcov-angelman-cum.png&#34; alt=&#34;angelman cumulate&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Since much of the chromosome is not covered due to the acrocentric chromosomal region, the y-axis starts at about 0.8
for all samples. For most samples, it does not drop until about 1. This means that most samples are covered at about
1X for 80% of the genome. We can see the angelman sample because it drops earlier, plateau&amp;rsquo;s, and then meets up with
the rest of the samples around one. This plot is a more concise way to show the data. It appears side-by-side with the
depth plot in the HTML output of indexcov.&lt;/p&gt;

&lt;h2 id=&#34;bin-outliers&#34;&gt;Bin outliers&lt;/h2&gt;

&lt;p&gt;One thing we can see from the plots above for chromosome 15 is that some samples are frequently farther from the expected
coverage of 1. For those plots, the offending samples are pink and light tan colored. These also appear as the samples with
the least vertical lines as the pass through a coverage of 1 on the proportion-covered-at plot. &lt;code&gt;indexcov&lt;/code&gt; calculates a
single value for each sample to describe this behavior; it simply counts the number of 16KB autosomal regions for which the the
sample is outside of the range of 0.85 to 1.15. It also calculates the slope of the cumulative coverage plot, but the 0.85-1-15 metric
seems to work quite well. It also calculates the proportion of bins with coverage &amp;lt; 0.15. This is useful for finding samples
with a lot of missing data. It then makes a plot of those 2 values. For the 45 sample cohort above, that looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/indexcov-bin.png&#34; alt=&#34;bin plot&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Note that there are 2 samples that are very high on the y-axis. Those correspond to the tan and pink and light-tan colored samples
that have variable coverage in the depth plots (in the HTML, this plot is hoverable so those samples are easily discoverable).&lt;/p&gt;

&lt;p&gt;Samples that are outliers like this have a &lt;em&gt;coverage bias&lt;/em&gt; that will make them problematic for CNV calling and likely other
prolems.&lt;/p&gt;

&lt;h2 id=&#34;chromosomal-differences&#34;&gt;Chromosomal Differences&lt;/h2&gt;

&lt;p&gt;Because &lt;code&gt;indexcov&lt;/code&gt; just does a simple per-sample median normalization (and because there are unknown coverage biases) some
variation in coverage still remains. This is especially apparent on chromosomes with high-GC content. For example, here is
chromosome 19, a high-GC chromosome, for the same 45-member cohort:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/indexcov-19.png&#34; alt=&#34;chr 19&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Note that there is extreme coverage variability in all samples, but especially in the tan sample. Don&amp;rsquo;t mistake
variability like this for an event, if you see a sample like that check if it&amp;rsquo;s high on the bin plot.&lt;/p&gt;

&lt;p&gt;(There does appear to be a true homozygous duplication in the rust-colored sample just after the centromere.)&lt;/p&gt;

&lt;h2 id=&#34;data-files&#34;&gt;Data Files&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;indexcov&lt;/code&gt; outputs data files (linked from the HTML). One is a ped file that contains all per-sample info:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;usual pedigree info with -9 for parents&lt;/li&gt;
&lt;li&gt;X and Y copy-number&lt;/li&gt;
&lt;li&gt;proportion of bins in and out of 0.85-1.15 range&lt;/li&gt;
&lt;li&gt;propotion of bins &amp;lt; 0.15&lt;/li&gt;
&lt;li&gt;slope of cumulative coverage line as it passes through 1.&lt;/li&gt;
&lt;li&gt;PCs 1 through 5&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;It also outputs a bed.gz file that an additional column for each sample and rows for each 16KB region in the genome so that
users can do their own analyses &lt;a href=&#34;https://twitter.com/yokofakun/status/975786108297596929&#34;&gt;and visualizations&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;use-it&#34;&gt;Use it&lt;/h2&gt;

&lt;p&gt;If you have whole genomes and haven&amp;rsquo;t used indexcov, give it a try. You can download a &lt;em&gt;truly&lt;/em&gt; static binary &lt;a href=&#34;https://github.com/brentp/goleft/releases&#34;&gt;here&lt;/a&gt;. And run it on a hundred bams in under 2 minutes like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;goleft indexcov -d output-dir/ /path/to/*.bam
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And, if you do use it, please cite &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/29048539&#34;&gt;the paper&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>mosdepth ideas</title>
      <link>/post/arrays/</link>
      <pubDate>Wed, 28 Mar 2018 20:12:07 -0600</pubDate>
      
      <guid>/post/arrays/</guid>
      
        <description>&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1739/29678184-da1f384c-88ba-11e7-9d98-df4fe3a59924.png&#34; alt=&#34;logo&#34; title=&#34;logo by tom sasani&#34; /&gt;&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m working on a new project and part of it is made possible by an observation that we
stumbled on with &lt;a href=&#34;https://github.com/brentp/mosdepth&#34;&gt;mosdepth&lt;/a&gt;. It&amp;rsquo;s something that&amp;rsquo;s obvious in retrospect
but wasn&amp;rsquo;t fully apparent to me until after &lt;code&gt;mosdepth&lt;/code&gt; was mostly written. In short, that observation is
&lt;em&gt;computers can do stuff with arrays quickly&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The longer story behind that obvious and simple observation is as follows. &lt;code&gt;mosdepth&lt;/code&gt; is a tool to calculate
depth from BAM/CRAM files. Rather than streaming out the coverage by keeping a heap of reads and keeping
a cursor in each read to indicate the position and popping reads off the heap as the cursor moves past the
end of the read and adding reads onto the heap as the genomic position advances, and &amp;hellip; [snip],
&lt;code&gt;mosdepth&lt;/code&gt; instead
allocates an array the size of the current chromosome, then considers each read one-at-a-time. For each,
it increments the read start position in the array by 1 and decrements then end position by 1 discards
that read, and proceeds with the next. Aaron used
this same algorithm in bedtools genome coverage which uses 2 arrays instead of 1. &lt;code&gt;mosdepth&lt;/code&gt;
does a bit more work for reads with deletions and reads that overlap their mate, but that&amp;rsquo;s it. Once
all reads from a chromosome are consumed and added, then the coverage is the cumulative sum of all elements
in the array.&lt;/p&gt;

&lt;p&gt;Given this array for human chromosome 1 which is over &lt;strong&gt;249 million bases&lt;/strong&gt; (or 249 million int32&amp;rsquo;s), in my laptop it takes about:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;0.125 seconds&lt;/strong&gt; to calculate this cumsum to convert the array values from start/end incr/decrs to per-base coverage&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;0.204 seconds&lt;/strong&gt; to calculate the mean coverage for each of &lt;strong&gt;111626&lt;/strong&gt; exons for all known transcripts on chromosome 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;0.756 seconds&lt;/strong&gt; to calculate quantized coverage (contiguous bins of coverage at specified depths) of &lt;code&gt;-q 0:1:2:3:4:5:6:7:8:12:16:20:25:30:40:&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;0.508&lt;/strong&gt; seconds to calculate the cumulative coverage distribution (proportion of bases covered at 1X, 2X&amp;hellip; $NX)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;hellip; and so on. So yeah, computers are good at arrays and stuff.&lt;/p&gt;

&lt;p&gt;We can add a lot of utility to &lt;code&gt;mosdepth&lt;/code&gt;, all of them in a single run and it doesn&amp;rsquo;t affect the runtime appreciably since (decompressing
and) parsing the bam dominate the run-time. Another benefit is that once everything is in the array, the times of all subsequent operations
are &lt;strong&gt;independent&lt;/strong&gt; of the depth. I didn&amp;rsquo;t realize all of these niceties until after it was mostly implemented.&lt;/p&gt;

&lt;p&gt;So, this is convenient. &lt;code&gt;mosdepth&lt;/code&gt; doesn&amp;rsquo;t have too much in the way of new ideas, it just takes full advantage. One
thing I realized later is that depth is a special case of a more generic thing we might want to measure. For depth,
we increment/decrement the start/end of each read (or the read&amp;rsquo;s component segments), but one could increment/decrement
the start/end of any event. For example the per-base locations of soft-clips/hard-clips/insertions/deletions, etc. I did
some of this in &lt;a href=&#34;https://github.com/brentp/bigly&#34;&gt;bigly&lt;/a&gt; which is based on the heap structure that we avoided with &lt;code&gt;mosdepth&lt;/code&gt;,
but next post, I&amp;rsquo;ll talk about what I&amp;rsquo;ll be working on and how it&amp;rsquo;s useful to do this in the &lt;code&gt;mosdepth&lt;/code&gt; way.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;p.s. thanks to &lt;a href=&#34;https://twitter.com/tomsasani&#34;&gt;Tom Sasani&lt;/a&gt; (AKA &lt;a href=&#34;https://www.nature.com/articles/nbt.4060&#34;&gt;sixsani&lt;/a&gt;)
for the logo and to Aaron for brainstorming sessions on what became the core of what became mosdepth&lt;/em&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Smoove</title>
      <link>/post/smoove/</link>
      <pubDate>Tue, 20 Mar 2018 16:49:22 -0600</pubDate>
      
      <guid>/post/smoove/</guid>
      
        <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/brentp/smoove&#34;&gt;smoove&lt;/a&gt; wraps existing software and adds some internal read-filtering to
&lt;strong&gt;simplify calling and genotyping structural variants&lt;/strong&gt;. It parallelizes each step as it can, for example, it
streams &lt;a href=&#34;https://github.com/arq5x/lumpy-sv&#34;&gt;lumpy&lt;/a&gt; output directly to multiple &lt;a href=&#34;https://github.com/hall-lab/svtyper&#34;&gt;svtyper&lt;/a&gt;
processes for genotyping.
It contains several sub-commands but users with cohorts of less than about 40 samples can get a
joint-called, genotyped VCF in a single command:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Bash&#34;&gt;smoove call -x --genotype --name $name --outdir . \
           -f $fasta --processes 12 --exclude $bed *.bam
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It also greatly simplifies population-level calling.
We have recently used &lt;code&gt;smoove&lt;/code&gt; to jointly call structural variants in &lt;strong&gt;2392 samples on AWS in about 1 hour of human time&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;This should work for any diploid species with a reference genome.&lt;/p&gt;

&lt;h4 id=&#34;filters-and-accuracy&#34;&gt;Filters and Accuracy&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;smoove&lt;/code&gt; uses &lt;code&gt;lumpy_filter&lt;/code&gt; from the &lt;a href=&#34;https://github.com/arq5x/lumpy-sv&#34;&gt;lumpy&lt;/a&gt;
repo to extract split (having a SA tag) and discordant (having an insert size outside of the expected range) reads as required
by lumpy. If &lt;code&gt;$sample.split.bam&lt;/code&gt; and &lt;code&gt;$sample.disc.bam&lt;/code&gt; are present (or soft-linked) to the output directory, then &lt;code&gt;smoove&lt;/code&gt; will use those
so output from &lt;a href=&#34;https://github.com/GregoryFaust/samblaster&#34;&gt;samblaster&lt;/a&gt; can be used to bypass the need for &lt;code&gt;lumpy_filter&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;It will then further filter those reads as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;reads where both ends are soft-clips are excluded, e.g. discard a read with cigar &lt;code&gt;20S106M34S&lt;/code&gt; but keep &lt;code&gt;87S123M&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;discard interchromosomal reads with &amp;gt; 3 mismatches (determined by NM sam tag).&lt;/li&gt;
&lt;li&gt;discard interchromosomal that also has an XA tag indicating alternative matches.&lt;/li&gt;
&lt;li&gt;discard interchromosomal split-reads are discarded unless the split (SA tag) goes to the same general location as the mate.&lt;/li&gt;
&lt;li&gt;remove reads in exclude regions or on excluded chromosomes.&lt;/li&gt;
&lt;li&gt;remove reads from regions where the depths of split or discordant reads is greater than 1000. This removes regions that
contribute to spurious calls.&lt;/li&gt;
&lt;li&gt;remove reads that are orphaned (dont have a mate) after all of the above filtering.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This removes more than &lt;strong&gt;80%&lt;/strong&gt; of the reads from the &lt;code&gt;.split.bam&lt;/code&gt; and &lt;code&gt;.disc.bam&lt;/code&gt; files that are sent to lumpy.
In our tests, compared to vanilla lumpy, we found
that, in a &lt;a href=&#34;http://eichlerlab.gs.washington.edu/publications/chm1-structural-variation/&#34;&gt;pac-bio derived truth set&lt;/a&gt;,
these filters removed about 4 ostensibly &lt;em&gt;true&lt;/em&gt; deletions out of 1191 while removing 120 out of 910 deletions that
were not found in the pac-bio data. There is also a considerable speed improvement and memory reduction using &lt;code&gt;smoove&lt;/code&gt;
as compared to vanilla &lt;code&gt;lumpy&lt;/code&gt;. We will do more work to filter even more reads (and perhaps add some missing ones)
to make this more efficient and accurate.&lt;/p&gt;

&lt;h4 id=&#34;usage&#34;&gt;Usage&lt;/h4&gt;

&lt;p&gt;The simplest way to get &lt;code&gt;smoove&lt;/code&gt; and all dependencies is via &lt;a href=&#34;https://hub.docker.com/r/brentp/smoove/&#34;&gt;dockerhub&lt;/a&gt; (and soon via bioconda).&lt;/p&gt;

&lt;p&gt;For a small cohort, the single command above is sufficient; for population-level calling, &lt;code&gt;smoove&lt;/code&gt; should be used to first call by
sample, or by family, or in groups of &lt;code&gt;n&lt;/code&gt; (we do this by family). Then it can extract and merge all sites from all groups (internally using
&lt;a href=&#34;https://github.com/hall-lab/svtools&#34;&gt;svtools&lt;/a&gt;). Then it can genotype at those sites (again, per sample or per small group),
and finally, it can create a square VCF using &lt;a href=&#34;https://github.com/samtools/bcftools&#34;&gt;bcftools&lt;/a&gt; merge.&lt;/p&gt;

&lt;p&gt;Each of these commands is documented in the &lt;a href=&#34;https://github.com/brentp/smoove&#34;&gt;smoove README&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;noise&#34;&gt;Noise&lt;/h4&gt;

&lt;p&gt;As indicated, I will look into additional read-filters that can be applied. If you know of or see a noise signal that could be
used to reliably remove reads that lead to spurious calls, please comment, or open an issue on the
&lt;a href=&#34;https://github.com/brentp/smoove&#34;&gt;smoove repo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In calling the 2392 samples mentioned above, it is clear that there are several avenues to explore for filtering. One noise signature that appears to be
associated with bad calls is when a variant has a low allele balance (hovering around 0.1) in many samples and never approaches the expected value
of 0.5. Though we expect mapping bias, it should not be this severe; signals like this are indicative of low-level noise causing spurious calls.
We can also look at the relative rates of split and discordant reads in these types of variants. In addition, I am working on another way to mitigate this
type of noise that is upstream of variant-calling that I will blog about soon.&lt;/p&gt;

&lt;h4 id=&#34;future&#34;&gt;Future&lt;/h4&gt;

&lt;p&gt;We may also wrap additional tools such as a depth-based CNV caller (something I plan on looking into writing this year) or other SV callers that complement
what &lt;a href=&#34;https://github.com/arq5x/lumpy-sv&#34;&gt;lumpy&lt;/a&gt; reports. Suggestions on this are also welcome.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Noise</title>
      <link>/post/noise/</link>
      <pubDate>Wed, 14 Mar 2018 19:35:37 -0600</pubDate>
      
      <guid>/post/noise/</guid>
      
        <description>&lt;p&gt;This afternoon, I did a quick analysis to attempt to find variants on the X chromosome that are under
recessive constraint&amp;ndash;that is that they appear in some non-zero frequency in females but never
occur in male. That is, without an extra copy, a variant might be embryonic lethal in males, but
could be seen in females thanks to a backup copy. I thought that these might be occurring at a
relatively high allele frequency (greater than 0.001). I encountered some surprises.&lt;/p&gt;

&lt;p&gt;A reasonable first pass is to filter to variants on X that have:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;0 homozygous alternate samples in females (or males)&lt;/li&gt;
&lt;li&gt;0 heterozygous alternate samples in males.&lt;/li&gt;
&lt;li&gt;some number of heterozygous sites in females.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This information is easily extracted from the &lt;a href=&#34;http://gnomad.broadinstitute.org/downloads&#34;&gt;gnomad exomes VCF&lt;/a&gt;
with 120K samples
as it reports &lt;code&gt;GC_Male&lt;/code&gt; and &lt;code&gt;GC_Female&lt;/code&gt;
which, for bi-allelic variants, have 3 values indicating the number of samples that
are respectively homozygous reference, heterozygous, and homozygous alternate.&lt;/p&gt;

&lt;p&gt;I created an expected proportion of alternate alleles (not samples) using the females and then used that
as the expected success rate for testing if males were depleted for the allele. Since gnomad also reports
the total number of alleles in males and females (accounting already for the fact that males only have 1 allele),
it&amp;rsquo;s simple to put this into a binomial test&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import scipy.stats as ss
from cyvcf2 import VCF
vcf = VCF(&amp;quot;gnomad.vcf.gz&amp;quot;)
for v in vcf(&amp;quot;X:2781479-155701382&amp;quot;): # exclude PAR
    gcm = v.INFO[&amp;quot;GC_Male&amp;quot;]
    gcf = v.INFO[&amp;quot;GC_Female&amp;quot;]
    success_prob = gcf[1] / float(v.INFO[&amp;quot;AN_Female&amp;quot;])
    # 0 successes == 0 males with an alternate out of AN_Male alleles with p defined by females.
    p = ss.binom_test(0, v.INFO[&amp;quot;AN_Male&amp;quot;], p=success_prob)
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are other ways to do this, but I figured this was a reasonable check to start&lt;/p&gt;

&lt;p&gt;After requiring a p-value of &amp;lt; 1e-10 to more than account for multiple testing, more than 500 variants popped
out.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://gnomad.broadinstitute.org/variant/X-14937753-T-G&#34;&gt;here&lt;/a&gt; is one of the top variants. It has an allele frequency
of 0.01553 but has never been seen as a homozygous alternate in 147,273 sampled alleles.&lt;/p&gt;

&lt;p&gt;What Aaron noticed after I sent a message to slack indicating that I&amp;rsquo;d solved the genome was that it always occurs on
the red (forward) reads in the alignment browser at the bottom of that page. Although this variant has PASS in the FILTER
field it has an FS of 172.927. &lt;code&gt;FS&lt;/code&gt; is &amp;ldquo;Phred-scaled p-value using Fisher&amp;rsquo;s exact test to detect strand bias&amp;rdquo;. High is bad.&lt;/p&gt;

&lt;p&gt;After requiring an FS &amp;lt;= 10, the number dropped dramatically, but there were still many variants. The next filter was to
require that the variant appear in gnomad whole genomes as we noticed that many of the candidates did not appear in whole genomes.
To have a high enough p-value to pass the 1e-10 threshold, the allele frequency should be high enough to appear in 12K samples.
After this, we also found that the remaining variants were frequently filtered in gnomad genomes VCF so we required them to be
present in the genomes, not flagged, and we again checked that there were 0 male heterozygotes or homozygous alternates in the
whole genomes as well. After this &lt;strong&gt;7 variants remained&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t inted to pursue this, but it was a fun afternoon&amp;rsquo;s tinkering. Here are those variants in case anyone has some
insight:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;X	2836140	rs202219772	G	A
X	48270249	rs377690870	G	A
X	101473058	rs782534766	A	G
X	119293216	rs782542106	C	CG
X	119293240	rs199940228	G	A
X	134988581	rs145404090	A	G
X	153461539	.	C	T
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://gist.github.com/brentp/e8b400bf8bfb297c8d49f9673e32d2e4#file-male-depleted-x-py&#34;&gt;here is the script used to find these&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>